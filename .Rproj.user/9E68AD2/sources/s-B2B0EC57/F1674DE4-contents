library(lme4)
#library(mvtnorm)
library(glmmTMB)
library(MASS)
library(numDeriv)
#library(blme)
#library(xtable)
#library(patchwork)
#library(scales)
#library(cowplot)
#library(ggplot2)
#library(memisc)
#library(dplyr)

library(optimx)
#library(brms)

#library(rstan)

 source("C:\\Users\\rblagus\\Dropbox (MF Uni LJ)\\Vienna2017\\MixedSeparation\\KosmidisIdea\\code/source_script_kosmidis.R")


#####################################
#####################################


##make psevdo data to implement Inverse-Wishart prior: not general!
###general function for q>1 (note, it does not work for q=1!)
#D0 a pdf matrix
#fact can be used to control the variance
#const a large positive constant to improve approximation
#note that internaly I rescale D0 so that I use true=qD0 to get the data!
#don't change fact, I think a further modification would be required!

make_pseudo_data_rand_eigen_general<-function(D0,fact=1,const=1e8){
  q<-nrow(D0)
  true=q*D0

  ee<-eigen(true,TRUE)
  ui<-list()
  for (j in 1:q){
    ui[[j]]<-sqrt(ee$values[j])*ee$vectors[,j]
  }

  #u1<-sqrt(ee$values[1])*ee$vectors[,1]
  #u2<-sqrt(ee$values[2])*ee$vectors[,2]

  #matrix(u1,ncol=1)%*%matrix(u1,nrow=1)+matrix(u2,ncol=1)%*%matrix(u2,nrow=1)
  pi0<-pi1<-list()
  for (j in 1:q){
    pi0[[j]]=exp(ui[[j]][1])/(1+exp(ui[[j]][1]))
    for (jj in 2:q){
      if (jj==2) pi1[[j]]<-exp(ui[[j]][jj])/((1-pi0[[j]])/pi0[[j]]+exp(ui[[j]][jj])) else pi1[[j]]=c(pi1[[j]],exp(ui[[j]][jj])/((1-pi0[[j]])/pi0[[j]]+exp(ui[[j]][jj])))
    }
  }
  #pi0=exp(u1[1])/(1+exp(u1[1]))
  #pi1=exp(u1[2])/((1-pi0)/pi0+exp(u1[2]))

  #pi02=exp(u2[1])/(1+exp(u2[1]))
  #pi12=exp(u2[2])/((1-pi02)/pi02+exp(u2[2]))

  #Y<-c(pi0,pi1,pi02,pi12)*1e8 #the constant improves the convergence!
  Y<-NA
  for (j in 1:q){
  Y<-c(Y,pi0[[j]],pi1[[j]])
    }
  Y<-Y[-1]

  #id<-c(1,1,2,2)
  id<-rep(1:q,each=q)
  n<-rep(const,length(id))
  Y<-Y*const

  Zi<-matrix(0,ncol=q,nrow=q)
  Zi[,1]<-1
  for (j in 2:q){
    Zi[j,j]<-1
  }
  for (j in 1:q){
    if (j==1) Z=Zi else Z<-rbind(Z,Zi)
  }

  if (fact>1){
    Y<-rep(Y,fact)
    n<-rep(n,fact)
    id<-rep(1:(q*fact),each=q)
    for (j in 1:(q*fact)){
      if (j==1) Z=Zi else Z<-rbind(Z,Zi)
    }
  }


  #Z<-rbind(c(1,0),c(1,1),c(1,0),c(1,1))
  data0<-list(Y=Y,grouping=id,nn=n,Z=Z)

  fit0<-glmer(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=data0,family=binomial)
  est.vcv<-VarCorr(fit0)$grouping[1:q,1:q]

  list(data=data0,fit=fit0,vcv.re=est.vcv)
}




make_pseudo_data_rand_eigen_general_v3<-function(D0,fact=1,const=1e8){
  q<-nrow(D0)
  true=q*D0

  ee<-eigen(true,TRUE)
  ui<-list()
  for (j in 1:q){
    ui[[j]]<-sqrt(ee$values[j])*ee$vectors[,j]
  }

  #u1<-sqrt(ee$values[1])*ee$vectors[,1]
  #u2<-sqrt(ee$values[2])*ee$vectors[,2]

  #matrix(u1,ncol=1)%*%matrix(u1,nrow=1)+matrix(u2,ncol=1)%*%matrix(u2,nrow=1)

  pi<-list()

  for (j in 1:length(ui)){
    I<-diag(rep(1,length(ui[[j]])))
    pi[[j]]<-1/(1+exp(-I%*%matrix(ui[[j]],ncol=1)))
  }

  ai<-list()

  for (j in 1:length(ui)){

    ai[[j]]<- q*solve(true)%*%matrix(ui[[j]],ncol=1)
  }


  #pi0=exp(u1[1])/(1+exp(u1[1]))
  #pi1=exp(u1[2])/((1-pi0)/pi0+exp(u1[2]))

  #pi02=exp(u2[1])/(1+exp(u2[1]))
  #pi12=exp(u2[2])/((1-pi02)/pi02+exp(u2[2]))

  #Y<-c(pi0,pi1,pi02,pi12)*1e8 #the constant improves the convergence!
  Y<-unlist(pi)

  #id<-c(1,1,2,2)
  id<-rep(1:q,each=q)
  n<-rep(const,length(id))
  Y<-Y*const+unlist(ai)

  Zi<-matrix(0,ncol=q,nrow=q)

  for (j in 1:q){
    Zi[j,j]<-1
  }
  for (j in 1:q){
    if (j==1) Z=Zi else Z<-rbind(Z,Zi)
  }

  if (fact>1){
    Y<-rep(Y,fact)
    n<-rep(n,fact)
    id<-rep(1:(q*fact),each=q)
    for (j in 1:(q*fact)){
      if (j==1) Z=Zi else Z<-rbind(Z,Zi)
    }
  }


  #Z<-rbind(c(1,0),c(1,1),c(1,0),c(1,1))
  data0<-list(Y=Y,grouping=id,nn=n,Z=Z)

  fit0<-glmer(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=data0,family=binomial)
  est.vcv<-VarCorr(fit0)$grouping[1:q,1:q]

  list(data=data0,fit=fit0,vcv.re=est.vcv)
}



#in this function no rescaling is performed, I use the matrix psi directly. fact controls the parameter nu: fact=1 gives nu=2q+1, or in general N=q*fact; q*fact=nu-q-1, nu=q*fact+q+1
#weights dont seem to matter.

make_pseudo_data_rand_eigen_general_psi<-function(psi,nu,const=1e8,param="precision"){
  if (is.null(match.arg(param,c("precision","variance")))) stop("param needs to be one of: precision,variance")

  q<-ncol(psi)
  if (param=="precision") cc<-(nu-q-1)/q
  if (param=="variance") cc<-(nu+q+1)/q

  cc<-max(c(floor(cc),1))
  if (param=="precision") true<-solve(psi)/cc
  if (param=="variance") true<-psi/cc
  ee<-eigen(true,TRUE)
  ui<-list()
  for (j in 1:q){
    ui[[j]]<-sqrt(ee$values[j])*ee$vectors[,j]
  }

  #u1<-sqrt(ee$values[1])*ee$vectors[,1]
  #u2<-sqrt(ee$values[2])*ee$vectors[,2]

  #matrix(u1,ncol=1)%*%matrix(u1,nrow=1)+matrix(u2,ncol=1)%*%matrix(u2,nrow=1)
  pi0<-pi1<-list()
  for (j in 1:q){
    pi0[[j]]=exp(ui[[j]][1])/(1+exp(ui[[j]][1]))
    for (jj in 2:q){
      if (jj==2) pi1[[j]]<-exp(ui[[j]][jj])/((1-pi0[[j]])/pi0[[j]]+exp(ui[[j]][jj])) else pi1[[j]]=c(pi1[[j]],exp(ui[[j]][jj])/((1-pi0[[j]])/pi0[[j]]+exp(ui[[j]][jj])))
    }
  }
  #pi0=exp(u1[1])/(1+exp(u1[1]))
  #pi1=exp(u1[2])/((1-pi0)/pi0+exp(u1[2]))

  #pi02=exp(u2[1])/(1+exp(u2[1]))
  #pi12=exp(u2[2])/((1-pi02)/pi02+exp(u2[2]))

  #Y<-c(pi0,pi1,pi02,pi12)*1e8 #the constant improves the convergence!
  Y<-NA
  for (j in 1:q){
    Y<-c(Y,pi0[[j]],pi1[[j]])
  }
  Y<-Y[-1]

  #id<-c(1,1,2,2)
  id<-rep(1:q,each=q)
  n<-rep(const,length(id))
  Y<-Y*const

  Zi<-matrix(0,ncol=q,nrow=q)
  Zi[,1]<-1
  for (j in 2:q){
    Zi[j,j]<-1
  }
  for (j in 1:q){
    if (j==1) Z=Zi else Z<-rbind(Z,Zi)
  }
  fact<-cc
  if (fact>1){
    Y<-rep(Y,fact)
    n<-rep(n,fact)
    id<-rep(1:(q*fact),each=q)
    for (j in 1:(q*fact)){
      if (j==1) Z=Zi else Z<-rbind(Z,Zi)
    }
  }

  #M<-rep(1/q,length(Y))
  #Z<-rbind(c(1,0),c(1,1),c(1,0),c(1,1))
  #data0<-list(Y=Y,grouping=id,nn=n,Z=Z,M=M)
  data0<-list(Y=Y,grouping=id,nn=n,Z=Z)

  #fit0<-glmmTMB(cbind(Y,nn-Y)~-1+(-1+Z|grouping),weights=M,data=data0,family=binomial)
  fit0<-glmmTMB(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=data0,family=binomial)
  est.vcv<-VarCorr(fit0)$cond$grouping[1:q,1:q]

  list(data=data0,fit=fit0,vcv.re=est.vcv)
}


#v3
make_pseudo_data_rand_eigen_general_psi_v3<-function(psi,nu,const=1e8,param="precision",use_correction=TRUE){
  if (is.null(match.arg(param,c("precision","variance")))) stop("param needs to be one of: precision,variance")

  q<-ncol(psi)
  if (param=="precision") cc<-(nu-q-1)/q
  if (param=="variance") cc<-(nu+q+1)/q

  cc<-max(c(floor(cc),1))
  if (param=="precision") true<-solve(psi)/cc
  if (param=="variance") true<-psi/cc
  ee<-eigen(true,TRUE)
  ui<-list()
  for (j in 1:q){
    ui[[j]]<-sqrt(ee$values[j])*ee$vectors[,j]
  }

  #u1<-sqrt(ee$values[1])*ee$vectors[,1]
  #u2<-sqrt(ee$values[2])*ee$vectors[,2]

  #matrix(u1,ncol=1)%*%matrix(u1,nrow=1)+matrix(u2,ncol=1)%*%matrix(u2,nrow=1)
  pi<-list()

  for (j in 1:length(ui)){
    I<-diag(rep(1,length(ui[[j]])))
    pi[[j]]<-1/(1+exp(-I%*%matrix(ui[[j]],ncol=1)))
  }
  #pi0=exp(u1[1])/(1+exp(u1[1]))
  #pi1=exp(u1[2])/((1-pi0)/pi0+exp(u1[2]))

  #pi02=exp(u2[1])/(1+exp(u2[1]))
  #pi12=exp(u2[2])/((1-pi02)/pi02+exp(u2[2]))
  if (use_correction==TRUE){
  ai<-list()
  if (param=="precision") var.cor<-psi else var.cor<-solve(psi)
  for (j in 1:length(ui)){

    ai[[j]]<- q*var.cor%*%matrix(ui[[j]],ncol=1)
  }
  } else {
    ai<-list()
    for (j in 1:length(ui)){

      ai[[j]]<- 0
    }
  }



  #Y<-c(pi0,pi1,pi02,pi12)*1e8 #the constant improves the convergence!
  Y<-unlist(pi)

  #id<-c(1,1,2,2)
  id<-rep(1:q,each=q)
  n<-rep(const,length(id))
  Y<-Y*const+unlist(ai)

  Zi<-matrix(0,ncol=q,nrow=q)

  for (j in 1:q){
    Zi[j,j]<-1
  }
  for (j in 1:q){
    if (j==1) Z=Zi else Z<-rbind(Z,Zi)
  }

  fact<-cc
  if (fact>1){
    Y<-rep(Y,fact)
    n<-rep(n,fact)
    id<-rep(1:(q*fact),each=q)
    for (j in 1:(q*fact)){
      if (j==1) Z=Zi else Z<-rbind(Z,Zi)
    }
  }

  #M<-rep(1/q,length(Y))
  #Z<-rbind(c(1,0),c(1,1),c(1,0),c(1,1))
  #data0<-list(Y=Y,grouping=id,nn=n,Z=Z,M=M)
  data0<-list(Y=Y,grouping=id,nn=n,Z=Z)

  #fit0<-glmmTMB(cbind(Y,nn-Y)~-1+(-1+Z|grouping),weights=M,data=data0,family=binomial)
  fit0<-glmmTMB(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=data0,family=binomial)
  est.vcv<-VarCorr(fit0)$cond$grouping[1:q,1:q]

  list(data=data0,fit=fit0,vcv.re=est.vcv)
}


make_pseudo_data_rand_eigen_general_psi_v3_glmm<-function(psi,nu,const=1e8,param="precision",link_fun=function(x) 1/(1+exp(-x))){
  if (is.null(match.arg(param,c("precision","variance")))) stop("param needs to be one of: precision,variance")

  q<-ncol(psi)
  if (param=="precision") cc<-(nu-q-1)/q
  if (param=="variance") cc<-(nu+q+1)/q

  cc<-max(c(floor(cc),1))
  if (param=="precision") true<-solve(psi)/cc
  if (param=="variance") true<-psi/cc
  ee<-eigen(true,TRUE)
  ui<-list()
  for (j in 1:q){
    ui[[j]]<-sqrt(ee$values[j])*ee$vectors[,j]
  }

  #u1<-sqrt(ee$values[1])*ee$vectors[,1]
  #u2<-sqrt(ee$values[2])*ee$vectors[,2]

  #matrix(u1,ncol=1)%*%matrix(u1,nrow=1)+matrix(u2,ncol=1)%*%matrix(u2,nrow=1)
  pi<-list()

  for (j in 1:length(ui)){
    I<-diag(rep(1,length(ui[[j]])))
    #pi[[j]]<-1/(1+exp(-I%*%matrix(ui[[j]],ncol=1)))
    pi[[j]]<-link_fun(I%*%matrix(ui[[j]],ncol=1))
  }
  #pi0=exp(u1[1])/(1+exp(u1[1]))
  #pi1=exp(u1[2])/((1-pi0)/pi0+exp(u1[2]))

  #pi02=exp(u2[1])/(1+exp(u2[1]))
  #pi12=exp(u2[2])/((1-pi02)/pi02+exp(u2[2]))


  #Y<-c(pi0,pi1,pi02,pi12)*1e8 #the constant improves the convergence!
  Y<-unlist(pi)

  #id<-c(1,1,2,2)
  id<-rep(1:q,each=q)
  n<-rep(const,length(id))

  Zi<-matrix(0,ncol=q,nrow=q)

  for (j in 1:q){
    Zi[j,j]<-1
  }
  for (j in 1:q){
    if (j==1) Z=Zi else Z<-rbind(Z,Zi)
  }

  fact<-cc
  if (fact>1){
    Y<-rep(Y,fact)
    n<-rep(n,fact)
    id<-rep(1:(q*fact),each=q)
    for (j in 1:(q*fact)){
      if (j==1) Z=Zi else Z<-rbind(Z,Zi)
    }
  }

  #M<-rep(1/q,length(Y))
  #Z<-rbind(c(1,0),c(1,1),c(1,0),c(1,1))
  #data0<-list(Y=Y,grouping=id,nn=n,Z=Z,M=M)
  data0<-list(Y=Y,grouping=id,nn=n,Z=Z)

  #fit0<-glmmTMB(cbind(Y,nn-Y)~-1+(-1+Z|grouping),weights=M,data=data0,family=binomial)
  #fit0<-glmmTMB(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=data0,family=binomial)
  #est.vcv<-VarCorr(fit0)$cond$grouping[1:q,1:q]

  list(data=data0)#,fit=fit0,vcv.re=est.vcv)
}




#example
psi<-rbind(c(10,2),c(2,3))

#data in psi param for nu=9

d1<-make_pseudo_data_rand_eigen_general_psi_v3(psi,nu=9,const=1e8,param="precision")
d2<-make_pseudo_data_rand_eigen_general_psi_v3(psi,nu=9,const=1e8,param="precision",use_correction=FALSE)
d22<-make_pseudo_data_rand_eigen_general_psi_v3_glmm(psi,nu=9,const=1e8,param="precision")
d222<-make_pseudo_data_rand_eigen_general_psi_v3_glmm(psi,nu=9,const=1e8,param="precision",link_fun = function(x) 1-exp(-exp(x)) )
d2222<-make_pseudo_data_rand_eigen_general_psi_v3_glmm(psi,nu=9,const=1e6,param="precision",link_fun = function(x) pnorm(x) )
dr<-make_pseudo_data_rand_eigen_general_psi_v3_glmm(psi,nu=9,const=1e8,param="precision",link_fun = function(x) exp(x) )


#make "long" data replicating the obs in each group and fit without using weights

Y<-d2$data$Y/d2$data$nn
group<-d2$data$grouping
Z<-d2$data$Z

replicates<-100000
for (i in 1:length(Y)){
  Yi<-rep(Y[i],replicates)
  groupi<-rep(group[i],replicates)
  Zi<-matrix(rep(Z[i,],replicates),ncol=ncol(Z),byrow=TRUE)

  if (i==1) {Y2<-Yi;group2<-groupi;Z2<-Zi} else {Y2<-c(Y2,Yi);group2<-c(group2,groupi);Z2<-rbind(Z2,Zi)}

}

data_group<-list(Y=Y2,grouping=group2,Z=Z2)
fitg<-glmer(Y~-1+(-1+Z|grouping),data=data_group,family=binomial(link="logit"))

fitg
ranef(fitg)
#ranef seem ok, but D is not (is it due to small number of replicates? or is it since I dont understand what we are doing?)
#no even when we increase n we get wrong D (but correct REs), which would imply that frequency weigts are indeed not what we need, but we really need precision weights.
###

fit<-glmer(Y/nn~-1+(-1+Z|grouping),data=d2$data,family=binomial(link="logit"),weights = nn)
fit2<-glmer(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=d2$data,family=binomial(link="logit"))
fit22<-glmer(Y~-1+(-1+Z|grouping),weights = nn,data=d22$data,family=binomial(link="logit"))
fit222<-glmer(Y~-1+(-1+Z|grouping),weights = nn,data=d222$data,family=binomial(link="cloglog"))
fit2222<-glmer(Y~-1+(-1+Z|grouping),weights = nn,data=d2222$data,family=binomial(link="probit"))

fit2222<-glmer(Y~-1+(-1+Z|grouping),weights = nn,data=d2222$data,family=binomial(link="logit"))
#use logit link to make data, but some other to fit
fit222.1<-glmer(Y~-1+(-1+Z|grouping),weights = nn,data=d22$data,family=binomial(link="cloglog"))
fit222.2<-glmer(Y~-1+(-1+Z|grouping),weights = nn,data=d22$data,family=binomial(link="probit"))



fitdr<-glmer(Y~-1+(-1+Z|grouping),weights = nn,data=dr$data,family=Gamma(link="log")) #it doesn seem to work for gamma, which would make sense due to phi not being 1! it seems that this is a limitation!

#it obviously works with all these link functions, it also works for poisson:

d22p<-make_pseudo_data_rand_eigen_general_psi_v3_glmm(psi,nu=9,const=1e6,param="precision",link_fun = function(x) exp(x))

#fitp<-glmer(Y~-1+(-1+Z|grouping),data=d22p$data,family=poisson(link="log"),weights = nn,control = glmerControl(check.response.not.const = "ignore"))
fitp<-glmmTMB(Y~-1+(-1+Z|grouping),data=d22p$data,family=poisson(link="log"),weights = nn)
#ok with TMB not with glmer!
d22p$data$Y<-exp(log(d22p$data$Y)+30)
d22p$data$ofset<-rep(log(30),length(d22p$data$Y))
fitp<-glmmTMB(Y~-1+offset(ofset)+(-1+Z|grouping),data=d22p$data,family=poisson(link="log"),weights = nn)
#this offseting is not ok!

#this offseting is ok
d22p<-make_pseudo_data_rand_eigen_general_psi_v3_glmm(psi,nu=9,const=1e8,param="precision",link_fun = function(x) exp(x))
d22p$data$Y<-d22p$data$Y*d22p$data$nn
d22p$data$ofset<-log(d22p$data$nn)

fitp<-glmmTMB(Y~-1+offset(ofset)+(-1+Z|grouping),data=d22p$data,family=poisson(link="log") )
#it also works for glmer
d22p$data$Y2<-round(d22p$data$Y)
fitp<-glmer(Y2~-1+offset(ofset)+(-1+Z|grouping),data=d22p$data,family=poisson(link="log"),control = glmerControl(check.response.not.const = "ignore"))

#if we also use weights we get issues.
fitp<-glmmTMB(Y~-1+offset(ofset)+(-1+Z|grouping),weights=nn,data=d22p$data,family=poisson(link="log") )
fitp<-glmer(Y2~-1+offset(ofset)+(-1+Z|grouping),weights=nn,data=d22p$data,family=poisson(link="log"),control = glmerControl(check.response.not.const = "ignore"))


solve(VarCorr(fitp)$grouping[1:2,1:2])


solve(VarCorr(fitp)$cond$grouping[1:2,1:2])

VarCorr(fitp)$cond$grouping[1:2,1:2]
solve(psi)/(9-2-1)

#note that the estimate of D- obtained only on pseudo
solve(d1$vcv.re)
solve(d2$vcv.re)
#is the same as the mode of W
psi*(9-2-1)

#due to relation between W and IW the MLE of D
d1$vcv.re
d2$vcv.re
#also corresponds to the mean of IW
solve(psi)/(9-2-1)

#data in var for nu=9
#psi<-rbind(c(1,.2),c(.2,3))


d21<-make_pseudo_data_rand_eigen_general_psi_v3(psi,nu=9,const=1e8,param="variance")
d22<-make_pseudo_data_rand_eigen_general_psi_v3(psi,nu=9,const=1e8,param="variance",use_correction = FALSE)
#in this case the MLE of D obtained only on pseudo
d21$vcv.re
d22$vcv.re
#corresponds to the mode of the IW
psi/(9+2+1)

#what about gama? it seems ok, maybe not...In fact the estimated REs are correct (the same as us which we use to determine ys), but then the estimated D is weird, why?

?glmer

lp<-x<-runif(100)
y<-1/lp
id<-sample(c(1:10),size=100,replace=TRUE)
z<-matrix(rep(1,100),ncol=1)
df<-list(Y=y,X=cbind(1,x),Z=z,grouping=id)
d2222<-make_pseudo_data_rand_eigen_general_psi_v3_glmm(psi,nu=9,const=1e8,param="precision",link_fun = function(x) exp(x) )

d2222$data$Y2<-d2222$data$Y*100
d2222$data$ofset<-rep(log(100),length(d2222$data$Y))

fit0<-glmer(Y~-1+(-1+Z|grouping),data=d2222$data,weights=nn,family=Gamma(link="log"),
            control=glmerControl(check.nobs.vs.nlev ="ignore",
                                 check.nlev.gtr.1 ="ignore",check.nobs.vs.nRE="ignore"))
fit0<-glmmTMB(Y~-1+(-1+Z|grouping),data=d2222$data,weights=nn,family=Gamma(link="log"))
fit01<-glmmTMB(Y2~-1+offset(ofset)+(-1+Z|grouping),data=d2222$data,weights=nn,family=Gamma(link="log"))
#note that the offseting works (as it does for the poisson model)

d2222$data$Y3<-d2222$data$Y*d2222$data$Y
d2222$data$ofset3<-log(d2222$data$Y)

fit02<-glmmTMB(Y3~-1+offset(ofset3)+(-1+Z|grouping),data=d2222$data,weights=nn,family=Gamma(link="log"))
#also works fine, why cant we make it work with inverse link??

#ranef are fine here!
VarCorr(fit0)$cond$grouping[1:2,1:2]
solve(psi)/(9-2-1)


##erik's result
d2222<-make_pseudo_data_rand_eigen_general_psi_v3_glmm(psi,nu=9,const=1e8,param="precision",link_fun = function(x) 1/exp(x) )
fit0<-glmmTMB(Y~-1+(-1+Z|grouping),data=d2222$data,weights=nn,family=Gamma(link="inverse"))



#with log link the offseting as for poisson should also work (obviously we dont need to round!)?
d2222$data$Y2<-d2222$data$Y*d2222$data$nn
d2222$data$ofset<-log(d2222$data$nn)

fit01<-glmmTMB(Y2~-1+offset(ofset)+(-1+Z|grouping),data=d2222$data,family=Gamma(link="log"))
#no, not ok (convergence issue?)
fit01<-glmer(Y2~-1+offset(ofset)+(-1+Z|grouping),data=d2222$data,family=Gamma(link="log"),
              control=glmerControl(check.nobs.vs.nlev ="ignore",
                                                 check.nlev.gtr.1 ="ignore",check.nobs.vs.nRE="ignore"))
#yes, this seems ok (still an issue with the estimate of D)

#what about this, taking care also of the diseprsion in TMB
fit01t<-glmmTMB(Y2~-1+offset(ofset)+(-1+Z|grouping),data=d2222$data,family=Gamma(link="log"),doFit = FALSE)

fit01t$data.tmb$doffset <- -log(d2222$data$nn)

fit2 <- glmmTMB:::fitTMB(fit01t)
#no, its not ok

fit0<-glmmTMB(Y~-1+(-1+Z|grouping),data=d2222$data,family=Gamma(link="log"),doFit = FALSE)
fit0$data.tmb$doffset <- -log(d2222$data$nn)

fit2 <- glmmTMB:::fitTMB(fit0)
#also not ok, and its exactly the same as above (since with the offseting we achieve the same thing)



#note that now using weights or not gives the same res in terms of REs, but it gives different D (neither is ok)
fit011<-glmer(Y2~-1+offset(ofset)+(-1+Z|grouping),weights=nn,data=d2222$data,family=Gamma(link="log"),
             control=glmerControl(check.nobs.vs.nlev ="ignore",
                                  check.nlev.gtr.1 ="ignore",check.nobs.vs.nRE="ignore"))

fit012<-glmer(Y2~-1+offset(ofset)+(-1+Z|grouping),data=d2222$data,family=Gamma(link="log"),
              control=glmerControl(check.nobs.vs.nlev ="ignore",
                                   check.nlev.gtr.1 ="ignore",check.nobs.vs.nRE="ignore"))


fit01<-glmmTMB(Y~-1+(-1+Z|grouping)+offset(-log(nn)),data=d2222$data,family=Gamma(link="log"))
#offseting here does not work!

tmp2 <- glmmTMB(Y~-1+(-1+Z|grouping),data=d2222$data, family=Gamma(link="log"),
                 doFit=FALSE )




tmp2$data.tmb$doffset <- -log(d2222$data$nn)

fit2 <- glmmTMB:::fitTMB(tmp2)



fit0<-glmer(Y~-1+(-1+Z|grouping),data=d2222$data,weights=nn,family=inverse.gaussian(link="log"),
            control=glmerControl(check.nobs.vs.nlev ="ignore",
                                 check.nlev.gtr.1 ="ignore",check.nobs.vs.nRE="ignore"))



#get D by hand:

res<-as.matrix(ranef(fit0)$cond$grouping) #TMB
D<-matrix(0,nrow=2,ncol=2)
for (i in 1:nrow(res)){
  D<-D+matrix(res[i,],nrow=2)%*%matrix(res[i,],ncol=2)
}

solve(D/nrow(res))
psi*(9-3) #the same as above, but different than
solve(VarCorr(fit0)$cond$grouping[1:2,1:2])
#so we definitively get the correct REs for the PC, but this does not necessarily give the correct D (it does for LM, logist, poisson, but not here, why??)


#use offset with inverse link
lp<-x<-runif(100)
y<-1/lp
id<-sample(c(1:10),size=100,replace=TRUE)
z<-matrix(rep(1,100),ncol=1)
df<-list(Y=y,X=cbind(1,x),Z=z,grouping=id)
d2222<-make_pseudo_data_rand_eigen_general_psi_v3_glmm(psi,nu=9,const=1e8,param="precision",link_fun = function(x) 1/x )

d2222$data$Y2<-1/(d2222$data$Y+200)
d2222$data$ofset<-  rep(200,length(d2222$data$Y2))


fit0<-glmmTMB(Y2~-1+(-1+Z|grouping),offset=ofset,data=d2222$data,weights=nn,family=Gamma(link="inverse"))
fit0<-glmer(Y2~-1+offset(ofset)+(-1+Z|grouping),data=d2222$data,weights=nn,family=Gamma(link="inverse"))
#given that REs are not centered around zero, I would assume this is the coding error

d2222$data$Y3<-d2222$data$Y*d2222$data$Y
d2222$data$ofset3<-(1-d2222$data$Y)/d2222$data$Y^2

fit01<-glmmTMB(Y3~-1+offset(ofset3)+(-1+Z|grouping),data=d2222$data,weights=nn,family=Gamma(link="inverse"))
#finally, this works (for the REs)


d2222<-make_pseudo_data_rand_eigen_general_psi_v3_glmm(psi,nu=9,const=1e6,param="precision",link_fun = function(x) exp(x) )
#does this still work? no, the scaling affects the ests. what if wescale prior to link? no, it still does not work

d2222$data$Y<- d2222$data$Y+30
d2222$data$ofset<-rep(30,length(d2222$data$Y))

fit0<-glmer(Y~-1+(-1+Z|grouping),data=d2222$data,weights=nn,family=Gamma(link="log"),
            control=glmerControl(check.nobs.vs.nlev ="ignore",
                                 check.nlev.gtr.1 ="ignore",check.nobs.vs.nRE="ignore"))

#no, this does not seem to work.


fit<-glmer(Y~-1+X+(-1+Z|grouping),data=df,family=Gamma(link="inverse"))
fitp<-glmmTMB(Y~-1+(-1+Z|grouping),data=d2222$data,family=Gamma(link="inverse"),weights = nn)


d2222<-make_pseudo_data_rand_eigen_general_psi_v3_glmm(psi,nu=5,const=1e8,param="precision",link_fun = function(x) x )

#this works
fit0<-lmer(Y~-1+(-1+Z|grouping),data=d2222$data,weights=nn,REML=FALSE,control=lmerControl(check.nobs.vs.nlev ="ignore",
                                                                                          check.nlev.gtr.1 ="ignore",check.nobs.vs.nRE="ignore"))
#this does not work
fit0<-glmer(Y~-1+(-1+Z|grouping),data=d2222$data,weights=nn,family=gaussian(link="identity"),
            control=glmerControl(check.nobs.vs.nlev ="ignore",
              check.nlev.gtr.1 ="ignore",check.nobs.vs.nRE="ignore"))

d2222$data$Y<- d2222$data$Y+30
d2222$data$ofset<-rep(30,length(d2222$data$Y))


fit0<-lmer(Y~-1+(-1+Z|grouping),data=d2222$data,weights=nn,REML=FALSE,control=lmerControl(check.nobs.vs.nlev ="ignore",    check.nlev.gtr.1 ="ignore",check.nobs.vs.nRE="ignore"))
#it also does not work with lm!
fit0<-lmer(Y~-1+offset(ofset)+(-1+Z|grouping),data=d2222$data,weights=nn,REML=FALSE,control=lmerControl(check.nobs.vs.nlev ="ignore",    check.nlev.gtr.1 ="ignore",check.nobs.vs.nRE="ignore"))
#yes, it works if we use the ofset!

fit<-glmer(Y~-1+X+(-1+Z|grouping),data=df,family=gaussian(link="identity"))
fit<-glmer(Y~-1+(-1+Z|grouping),data=d2222$data,weights = nn,family=gaussian(link="identity"),
           control=glmerControl(check.nobs.vs.nlev="ignore"))



##cholesky, different clusters but the same end result

make_pseudo_data_rand_eigen_general_psi_chol<-function(psi,nu,const=1e8,param="precision"){
  if (is.null(match.arg(param,c("precision","variance")))) stop("param needs to be one of: precision,variance")

  q<-ncol(psi)
  if (param=="precision") cc<-(nu-q-1)/q
  if (param=="variance") cc<-(nu+q+1)/q

  cc<-max(c(floor(cc),1))
  if (param=="precision") true<-solve(psi)/cc
  if (param=="variance") true<-psi/cc
  ee<-chol(true)
  ui<-list()
  for (j in 1:q){
    ui[[j]]<-ee[j,]
  }

  #u1<-sqrt(ee$values[1])*ee$vectors[,1]
  #u2<-sqrt(ee$values[2])*ee$vectors[,2]

  #matrix(u1,ncol=1)%*%matrix(u1,nrow=1)+matrix(u2,ncol=1)%*%matrix(u2,nrow=1)
  pi0<-pi1<-list()
  for (j in 1:q){
    pi0[[j]]=exp(ui[[j]][1])/(1+exp(ui[[j]][1]))
    for (jj in 2:q){
      if (jj==2) pi1[[j]]<-exp(ui[[j]][jj])/((1-pi0[[j]])/pi0[[j]]+exp(ui[[j]][jj])) else pi1[[j]]=c(pi1[[j]],exp(ui[[j]][jj])/((1-pi0[[j]])/pi0[[j]]+exp(ui[[j]][jj])))
    }
  }
  #pi0=exp(u1[1])/(1+exp(u1[1]))
  #pi1=exp(u1[2])/((1-pi0)/pi0+exp(u1[2]))

  #pi02=exp(u2[1])/(1+exp(u2[1]))
  #pi12=exp(u2[2])/((1-pi02)/pi02+exp(u2[2]))

  #Y<-c(pi0,pi1,pi02,pi12)*1e8 #the constant improves the convergence!
  Y<-NA
  for (j in 1:q){
    Y<-c(Y,pi0[[j]],pi1[[j]])
  }
  Y<-Y[-1]

  #id<-c(1,1,2,2)
  id<-rep(1:q,each=q)
  n<-rep(const,length(id))
  Y<-Y*const

  Zi<-matrix(0,ncol=q,nrow=q)
  Zi[,1]<-1
  for (j in 2:q){
    Zi[j,j]<-1
  }
  for (j in 1:q){
    if (j==1) Z=Zi else Z<-rbind(Z,Zi)
  }
  fact<-cc
  if (fact>1){
    Y<-rep(Y,fact)
    n<-rep(n,fact)
    id<-rep(1:(q*fact),each=q)
    for (j in 1:(q*fact)){
      if (j==1) Z=Zi else Z<-rbind(Z,Zi)
    }
  }

  #M=rep(1/q,length(Y))
  #Z<-rbind(c(1,0),c(1,1),c(1,0),c(1,1))
  #data0<-list(Y=Y,grouping=id,nn=n,Z=Z,M=M)
  data0<-list(Y=Y,grouping=id,nn=n,Z=Z)

  #fit0<-glmmTMB(cbind(Y,nn-Y)~-1+(-1+Z|grouping),weights=M,data=data0,family=binomial)
  fit0<-glmmTMB(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=data0,family=binomial)
  est.vcv<-VarCorr(fit0)$cond$grouping[1:q,1:q]

  list(data=data0,fit=fit0,vcv.re=est.vcv)
}

#example
psi<-rbind(c(10,2),c(2,3))

#data in psi param for nu=9

d1<-make_pseudo_data_rand_eigen_general_psi_chol(psi,nu=9,const=1e8,param="precision")
#note that the estimate of D- obtained only on pseudo
solve(d1$vcv.re)
#is the same as the mode of W
psi*(9-2-1)

#due to relation between W and IW the MLE of D
d1$vcv.re
#also corresponds to the mean of IW
solve(psi)/(9-2-1)

#data in var for nu=9
#psi<-rbind(c(1,.2),c(.2,3))


d2<-make_pseudo_data_rand_eigen_general_psi_chol(psi,nu=9,const=1e8,param="variance")
#in this case the MLE of D obtained only on pseudo
d2$vcv.re
#corresponds to the mode of the IW
psi/(9+2+1)

#is it the same also when we add Xs? it seems the same (checked on Kos example)



psi<-rbind(c(10,2),c(2,3))

#data in psi param for nu=9

d1<-make_pseudo_data_rand_eigen_general_psi(psi,nu=9,const=1e8,param="precision")
#note that the estimate of D- obtained only on pseudo
solve(d1$vcv.re)
#is the same as the mode of W
psi*(9-2-1)

#due to relation between W and IW the MLE of D
d1$vcv.re
#also corresponds to the mean of IW
solve(psi)/(9-2-1)

#data in var for nu=9
#psi<-rbind(c(1,.2),c(.2,3))


d2<-make_pseudo_data_rand_eigen_general_psi_chol(psi,nu=9,const=1e8,param="variance")
#in this case the MLE of D obtained only on pseudo
d2$vcv.re
#corresponds to the mode of the IW
psi/(9+2+1)



####pseudo data only for random intercept: note you cannot fit lmer only to pseudodata since there is only one cluster, but you can still check by fitting to all and calculating the variance by yourself!

make_pseudo_data_rand_eigen_inter<-function(var.int,fact=1,const=1e8){

  true=matrix(var.int,ncol=1,nrow=1)

  ee<-eigen(true,TRUE)
  u1<-sqrt(ee$values[1])*ee$vectors[,1]
  #u2<-sqrt(ee$values[2])*ee$vectors[,2]

  #matrix(u1,ncol=1)%*%matrix(u1,nrow=1)+matrix(u2,ncol=1)%*%matrix(u2,nrow=1)


  pi0=exp(u1[1])/(1+exp(u1[1]))

  Y<-rep(c(pi0)*const,fact) #the constant improves the convergence!
  n<-rep(rep(const,1),fact)
  id<-c(1:fact)
  Z<-matrix(rep(1,fact),ncol=1)
  data0<-list(Y=Y,grouping=id,nn=n,Z=Z)

  #fit0<-glmer(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=data0,family=binomial)
  #est.vcv<-VarCorr(fit0)$grouping[1:2,1:2]

  list(data=data0)#,fit=fit0,vcv.re=est.vcv)
}




make_pseudo_data_rand_eigen_inter_v3<-function(var.int,fact=1,const=1e8){

  true=matrix(var.int,ncol=1,nrow=1)

  ee<-eigen(true,TRUE)
  u1<-sqrt(ee$values[1])*ee$vectors[,1]
  #u2<-sqrt(ee$values[2])*ee$vectors[,2]

  #matrix(u1,ncol=1)%*%matrix(u1,nrow=1)+matrix(u2,ncol=1)%*%matrix(u2,nrow=1)


  pi0=exp(u1[1])/(1+exp(u1[1]))

  Y<-rep(c(pi0)*const+1/u1[1],fact) #the constant improves the convergence!
  n<-rep(rep(const,1),fact)
  id<-c(1:fact)
  Z<-matrix(rep(1,fact),ncol=1)
  data0<-list(Y=Y,grouping=id,nn=n,Z=Z)

  #fit0<-glmer(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=data0,family=binomial)
  #est.vcv<-VarCorr(fit0)$grouping[1:2,1:2]

  list(data=data0)#,fit=fit0,vcv.re=est.vcv)
}




#param - in which parametrizaion should we work: psi, sigma2, logsigma2 (the same as log(sigma))

make_pseudo_data_rand_eigen_inter_alpha_beta<-function(alpha,beta,param="psi",const=1e8){
  if (is.null(match.arg(param,c("psi","sigma2","logsigma2")))) stop("param needs to be one of: psi,sigma2,logsigma2")

  if (param=="psi") N<-max(c(floor(2*(alpha-1)),1))
  if (param=="sigma2") N<-max(c(floor(2*(alpha+1)),1))
  if (param=="logsigma2") N<-max(c(floor(2*(alpha)),1))

  var.int<-beta*2/N
  fact<-N

  true=matrix(var.int,ncol=1,nrow=1)

  ee<-eigen(true,TRUE)
  u1<-sqrt(ee$values[1])*ee$vectors[,1]
  #u2<-sqrt(ee$values[2])*ee$vectors[,2]

  #matrix(u1,ncol=1)%*%matrix(u1,nrow=1)+matrix(u2,ncol=1)%*%matrix(u2,nrow=1)


  pi0=exp(u1[1])/(1+exp(u1[1]))

  Y<-rep(c(pi0)*const,fact) #the constant improves the convergence!
  n<-rep(rep(const,1),fact)
  id<-c(1:fact)
  Z<-matrix(rep(1,fact),ncol=1)
  data0<-list(Y=Y,grouping=id,nn=n,Z=Z)

  #fit0<-glmer(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=data0,family=binomial)
  #est.vcv<-VarCorr(fit0)$grouping[1:2,1:2]

  list(data=data0)#,fit=fit0,vcv.re=est.vcv)
}


#######################

####aux functions


 expit<-function(x) 1/(1+exp(-x))




####this is the implementation of Yefrey prior as in description_v3
#data - list with elements Y, X, Z, grouping, M
#penX - TRUE sets the penalty for beta, should results in ML for FALSE
#fit.TMB TRUE uses glmmTMB, FALSE uses glmer
#REML - only applies if fit.TMB=TRUE, if TRUE uses REML for variance components, if FALSE uses ML
#plot.coef.path - plots coefficient pats for each fixef parameter
#weight.c - the multiplies of the weight, a single number: common choice either 1/2 or sqrt(p/ntot)
#allglmm - TRUE - probs in hat are defined by the entire GLMM, FALSE - probs are defined only by fixef (as in Kos)


pen_X_only<-function(data,tol=1e-6,maxIter=25,penX=TRUE,allglmm=FALSE,weight.c=1/2,fit.TMB=FALSE,REML=FALSE,plot.coef.path=FALSE,nAGQ=1,optimizer=c("bobyqa", "Nelder_Mead")){


  xdf=data
  N<-length(unique(xdf$grouping))
  Ntot<-nrow(xdf$X)
  ##here the iterative procedure starts:
  if(penX==TRUE){

    pi0<-rep(0.5,Ntot)
    W<-diag(pi0*(1-pi0))
    #H<-(W%^%(1/2))%*%xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W%^%(1/2))
    H<-xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%W

    hi<-diag(H)

  } else {

    hi<-rep(0,Ntot)
  }

  ##add pseudoobsr:
  cfs<-list()


  flag=FALSE

  nIter<-0
  while(flag==FALSE&nIter<maxIter){
    nIter<-nIter+1

    ##add pseudoobsr:

    if (nIter==1) {
      #sigma_est2=0
      X=rbind(xdf$X,xdf$X,xdf$X)

      Z=rbind(xdf$Z,matrix(0,ncol=ncol(xdf$Z),nrow=Ntot*2)) #no penalty on Z

      Y=c(xdf$Y,xdf$Y,1-xdf$Y)
      M=c(xdf$M,hi*weight.c,hi*weight.c)
      grouping=c(xdf$grouping,
                 seq(from=1+max(xdf$grouping),by=1,length.out = 2*Ntot)
      )
      #grouping=rep(xdf$grouping,3) #old version, the new makes more sense (although the res are similar)


      pseudo<-list(X=X,
                   Z=Z,
                   Y=Y,
                   M=M,
                   grouping=grouping
      )


      if (fit.TMB==FALSE){
        gmm.fit0<-glmer(Y~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M ,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer,check.nobs.vs.nlev ="ignore",check.nlev.gtr.1="ignore",check.nobs.vs.nRE="ignore",check.response.not.const ="ignore"))
        est.vcv<-VarCorr(gmm.fit0)$grouping[1,1]
      } else {
        gmm.fit0<-glmmTMB(Y~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML)
        est.vcv<-VarCorr(gmm.fit0)$cond$grouping[1,1]
      }
    } else {
      gmm.fit0<-gmm.fit
    }
    if (fit.TMB==FALSE){
      cfs[[nIter]]<-fixef(gmm.fit0)
    } else {
      cfs[[nIter]]<-fixef(gmm.fit0)$cond
    }
    #xdf$lp<-predict(gmm.fit0,random.only=TRUE)[1:nrow(xdf$X)]
    #xdf$lp<-get.re(gmm.fit0,nrow(xdf$X),xdf$grouping,xdf$Z)

    if(penX==TRUE){
      if (fit.TMB==FALSE){
        if (allglmm==FALSE) {
          pi0<-predict(gmm.fit0,re.form = NA)[1:Ntot]} else {
            pi0<-predict(gmm.fit0)[1:Ntot]
          }
      } else {
        # pi0<-predict(gmm.fit0,newdata=xdf,re.form = NA)
        if (allglmm==TRUE) {
          pi0<-c(predict(gmm.fit0,newdata=xdf))} else {
            pi0<-c(xdf$X%*%matrix(fixef(gmm.fit0)$cond,ncol=1))
          }
      }
      pi0<-expit(pi0)
      W<-diag(pi0*(1-pi0))
      #H<-(W%^%(1/2))%*%xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W%^%(1/2))
      H<-xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
      hi<-diag(H)

    } else {

      hi<-rep(0,Ntot)
    }


    M=c(xdf$M,hi*weight.c,hi*weight.c)


    pseudo<-list(X=X,
                 Z=Z,
                 Y=Y,
                 M=M,
                 grouping=grouping
    )


    if (fit.TMB==FALSE){
      gmm.fit<-glmer(Y~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer,check.nobs.vs.nlev ="ignore",check.nlev.gtr.1="ignore",check.nobs.vs.nRE="ignore",check.response.not.const ="ignore") )
      tol2<-max(c(max(abs(fixef(gmm.fit0)-fixef(gmm.fit))),
                  max(abs(ranef(gmm.fit0)$grouping[1:N,]-ranef(gmm.fit)$grouping[1:N,])) ))


    } else {
      gmm.fit<-glmmTMB(Y~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML)

      tol2<-max(c(max(abs(fixef(gmm.fit0)$cond-fixef(gmm.fit)$cond)),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping[1:N,]-ranef(gmm.fit)[[1]]$grouping[1:N,])) ))

    }


    if (tol2<tol) flag=TRUE
  }

  if (fit.TMB==FALSE){
    cfs[[nIter+1]]<-fixef(gmm.fit)
  } else {
    cfs[[nIter+1]]<-fixef(gmm.fit)$cond
  }

  if (plot.coef.path==TRUE){
    pp<-length(cfs[[1]])
    ce<-matrix(unlist(cfs),byrow=TRUE,ncol=pp)
    par(mfrow=c(1,pp))
    for (i in 1:pp){
      plot(ce[,i],type="l")
    }

  }


  gmm.fit

}



#version where we add prior on Z, with fixef penalty as in description_v3

#psevdo_data_Z what you get from a call to either
#make_pseudo_data_rand_eigen_general for q>1 or
#make_pseudo_data_rand_eigen_inter for q=1
#the other params are as described for pen_X_only
#tol=1e-6
#maxIter=25
#penX=TRUE
#fit.TMB=FALSE
#REML=FALSE
#plot.coef.path=TRUE
#weight.c
#weight.z - weight to be applied to the penalty for RES (defaults to 1, but we could also use sqrt(p/nn))
#allglmm - TRUE - probs in hat are defined by the entire GLMM, FALSE - probs are defined only by fixef (as in Kos)

pen_both<-function(data,psevdo_data_Z,weight.c=1/2,allglmm=FALSE,weight.z=1,tol=1e-6,maxIter=25,penX=TRUE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=FALSE,nAGQ=1,optimizer=c("bobyqa", "Nelder_Mead")){

  # if (is.null(weightz)) weightz<-rep(1,length(psevdo_data_Z$data$Y))

  weightz<-rep(1,length(psevdo_data_Z$data$Y))*weight.z
  #weighth<-psevdo_data_Z$data$nn[1] #using this makes no sense at all, we get very weird results also for fixef!
  weighth<-1
  xdf=data
  N<-length(unique(xdf$grouping))
  Ntot<-nrow(xdf$X)
  ##here the iterative procedure starts:
  if(penX==TRUE){

    pi0<-rep(0.5,Ntot)
    W<-diag(pi0*(1-pi0))
    #H<- xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
    H<- xdf$X%*%ginv(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
    hi<-diag(H)

  } else {
    hi<-rep(0,Ntot)
  }

  ##add pseudoobsr:
  cfs<-list()


  flag=FALSE

  nIter<-0
  while(flag==FALSE&nIter<maxIter){
    nIter<-nIter+1

    ##add pseudoobsr:

    if (nIter==1) {

      X=rbind(xdf$X,xdf$X,xdf$X,matrix(0,ncol=ncol(xdf$X),nrow=nrow(psevdo_data_Z$data$Z)))

      ZZ=rbind(xdf$Z,matrix(0,ncol=ncol(xdf$Z),nrow=Ntot*2)) #no penalty on Z

      Z=rbind(ZZ,psevdo_data_Z$data$Z)
      Y=c(xdf$Y,xdf$Y,1-xdf$Y,psevdo_data_Z$data$Y)
      M=c(xdf$M*weighth,hi*weight.c*weighth,hi*weight.c*weighth,weightz)
      nn=c(rep(1,nrow(ZZ)),psevdo_data_Z$data$nn)
      groupingi=c(xdf$grouping,
                  seq(from=1+max(xdf$grouping),by=1,length.out = 2*Ntot)  )
      grouping=c(groupingi,psevdo_data_Z$data$grouping+max(groupingi))
      #grouping=rep(xdf$grouping,3) #old version, the new makes more sense (although the res are similar)


      pseudo<-list(X=X,
                   Z=Z,
                   Y=Y,
                   M=M,
                   grouping=grouping,
                   nn=nn
      )


      if (fit.TMB==FALSE){
        gmm.fit0<-glmer(cbind(Y,nn-Y)~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer,check.nobs.vs.nlev ="ignore",check.nlev.gtr.1="ignore",check.nobs.vs.nRE="ignore",check.response.not.const ="ignore") )
      } else {
        gmm.fit0<-glmmTMB(cbind(Y,nn-Y)~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML)
      }
    } else {
      gmm.fit0<-gmm.fit
    }
    if (fit.TMB==FALSE){
      cfs[[nIter]]<-fixef(gmm.fit0)
    } else {
      cfs[[nIter]]<-fixef(gmm.fit0)$cond
    }
    #xdf$lp<-predict(gmm.fit0,random.only=TRUE)[1:nrow(xdf$X)]
    #xdf$lp<-get.re(gmm.fit0,nrow(xdf$X),xdf$grouping,xdf$Z)

    if(penX==TRUE){

      if (fit.TMB==FALSE){
        if (allglmm==FALSE){
          pi0<-predict(gmm.fit0,re.form = NA)[1:Ntot]} else {
            pi0<-predict(gmm.fit0)[1:Ntot]
          }
      } else {
        #pi0<-predict(gmm.fit0,newdata=xdf,re.form = NA)
        if (allglmm==TRUE){
          pi0<-c(predict(gmm.fit0,newdata=xdf))} else {
            pi0<-c(xdf$X%*%matrix(fixef(gmm.fit0)$cond,ncol=1))
          }

      }
      pi0<-expit(pi0)
      W<-diag(pi0*(1-pi0))
      #H<-xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
      H<-xdf$X%*%ginv(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
      hi<-diag(H)

    } else {
      hi<-rep(0,Ntot)
    }

    M=c(xdf$M*weighth,hi*weight.c*weighth,hi*weight.c*weighth,weightz)


    pseudo<-list(X=X,
                 Z=Z,
                 Y=Y,
                 M=M,
                 grouping=grouping,
                 nn=nn
    )


    if (fit.TMB==FALSE){
      gmm.fit<-glmer(cbind(Y,nn-Y)~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer,check.nobs.vs.nlev ="ignore",check.nlev.gtr.1="ignore",check.nobs.vs.nRE="ignore",check.response.not.const ="ignore") )
      tol2<-max(c(max(abs(fixef(gmm.fit0)-fixef(gmm.fit))),
                  max(abs(ranef(gmm.fit0)$grouping[1:N,]-ranef(gmm.fit)$grouping[1:N,])) ))


    } else {
      gmm.fit<-glmmTMB(cbind(Y,nn-Y)~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML)

      tol2<-max(c(max(abs(fixef(gmm.fit0)$cond-fixef(gmm.fit)$cond)),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping[1:N,]-ranef(gmm.fit)[[1]]$grouping[1:N,])) ))

    }


    if (tol2<tol) flag=TRUE
  }

  if (fit.TMB==FALSE){
    cfs[[nIter+1]]<-fixef(gmm.fit)
  } else {
    cfs[[nIter+1]]<-fixef(gmm.fit)$cond
  }

  if (plot.coef.path==TRUE){
    pp<-length(cfs[[1]])
    ce<-matrix(unlist(cfs),byrow=TRUE,ncol=pp)
    par(mfrow=c(1,pp))
    for (i in 1:pp){
      plot(ce[,i],type="l")
    }

  }


  gmm.fit

}

#####allow 2 REs


pen_both_2res<-function(data,psevdo_data_Z,psevdo_data_Z_2,weight.c=1/2,allglmm=FALSE,weight.z=1,tol=1e-6,maxIter=25,penX=TRUE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=FALSE,nAGQ=1,optimizer=c("bobyqa", "Nelder_Mead")){

  # if (is.null(weightz)) weightz<-rep(1,length(psevdo_data_Z$data$Y))

  weightz<-rep(1,length(psevdo_data_Z$data$Y))*weight.z
  weightz_2<-rep(1,length(psevdo_data_Z_2$data$Y))*weight.z
  #weighth<-psevdo_data_Z$data$nn[1] #using this makes no sense at all, we get very weird results also for fixef!
  weighth<-1
  xdf=data
  N<-length(unique(xdf$grouping))
  Ntot<-nrow(xdf$X)
  ##here the iterative procedure starts:
  if(penX==TRUE){

    pi0<-rep(0.5,Ntot)
    W<-diag(pi0*(1-pi0))
    #H<- xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
    H<- xdf$X%*%ginv(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
    hi<-diag(H)

  } else {
    hi<-rep(0,Ntot)
  }

  ##add pseudoobsr:
  cfs<-list()


  flag=FALSE

  nIter<-0
  while(flag==FALSE&nIter<maxIter){
    nIter<-nIter+1

    ##add pseudoobsr:

    if (nIter==1) {

      X=rbind(xdf$X,xdf$X,xdf$X,matrix(0,ncol=ncol(xdf$X),
                                       nrow=nrow(psevdo_data_Z$data$Z)+nrow(psevdo_data_Z_2$data$Z)))

      ZZ=rbind(xdf$Z,matrix(0,ncol=ncol(xdf$Z),nrow=Ntot*2)) #no penalty on Z
      ZZ2=rbind(xdf$Z_2,matrix(0,ncol=ncol(xdf$Z_2),nrow=Ntot*2)) #no penalty on Z2

      ZZ_1=matrix(0,ncol=ncol(psevdo_data_Z$data$Z),nrow=nrow((psevdo_data_Z_2$data$Z)))
      ZZ_2=matrix(0,ncol=ncol(psevdo_data_Z_2$data$Z),nrow=nrow((psevdo_data_Z$data$Z)))

      Z=rbind(ZZ,psevdo_data_Z$data$Z,ZZ_1)
      Z_2=rbind(ZZ2,ZZ_2,psevdo_data_Z_2$data$Z)
      Y=c(xdf$Y,xdf$Y,1-xdf$Y,psevdo_data_Z$data$Y,psevdo_data_Z_2$data$Y)
      M=c(xdf$M*weighth,hi*weight.c*weighth,hi*weight.c*weighth,weightz,weightz_2)
      nn=c(rep(1,nrow(ZZ)),psevdo_data_Z$data$nn,psevdo_data_Z_2$data$nn)
      groupingi=c(xdf$grouping,
                  seq(from=1+max(xdf$grouping),by=1,length.out = 2*Ntot)  )
      grouping=c(groupingi,psevdo_data_Z$data$grouping+max(groupingi))
      grouping1=c(grouping,psevdo_data_Z_2$data$grouping+max(grouping))

      groupingi_2=c(xdf$grouping_2,
                  seq(from=1+max(xdf$grouping_2),by=1,length.out = 2*Ntot)  )
      grouping_2=c(groupingi_2,psevdo_data_Z$data$grouping+max(groupingi_2))
      grouping1_2=c(grouping_2,psevdo_data_Z_2$data$grouping+max(grouping_2))


      #grouping=rep(xdf$grouping,3) #old version, the new makes more sense (although the res are similar)


      pseudo<-list(X=X,
                   Z_1=Z,
                   Z_2=Z_2,
                   Y=Y,
                   M=M,
                   grouping_1=grouping1,
                   grouping_2=grouping1_2,
                   nn=nn
      )


      if (fit.TMB==FALSE){
        gmm.fit0<-glmer(cbind(Y,nn-Y)~-1+X+(-1+Z_1|grouping_1)+(-1+Z_2|grouping_2), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer,check.nobs.vs.nlev ="ignore",check.nlev.gtr.1="ignore",check.nobs.vs.nRE="ignore",check.response.not.const ="ignore") )
      } else {
        gmm.fit0<-glmmTMB(cbind(Y,nn-Y)~-1+X+(-1+Z_1|grouping_1)+(-1+Z_2|grouping_2), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML)
      }
    } else {
      gmm.fit0<-gmm.fit
    }
    if (fit.TMB==FALSE){
      cfs[[nIter]]<-fixef(gmm.fit0)
    } else {
      cfs[[nIter]]<-fixef(gmm.fit0)$cond
    }
    #xdf$lp<-predict(gmm.fit0,random.only=TRUE)[1:nrow(xdf$X)]
    #xdf$lp<-get.re(gmm.fit0,nrow(xdf$X),xdf$grouping,xdf$Z)

    if(penX==TRUE){

      if (fit.TMB==FALSE){
        if (allglmm==FALSE){
          pi0<-predict(gmm.fit0,re.form = NA)[1:Ntot]} else {
            pi0<-predict(gmm.fit0)[1:Ntot]
          }
      } else {
        #pi0<-predict(gmm.fit0,newdata=xdf,re.form = NA)
        if (allglmm==TRUE){
          pi0<-c(predict(gmm.fit0,newdata=xdf))} else {
            pi0<-c(xdf$X%*%matrix(fixef(gmm.fit0)$cond,ncol=1))
          }

      }
      pi0<-expit(pi0)
      W<-diag(pi0*(1-pi0))
      #H<-xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
      H<-xdf$X%*%ginv(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
      hi<-diag(H)

    } else {
      hi<-rep(0,Ntot)
    }


    M=c(xdf$M*weighth,hi*weight.c*weighth,hi*weight.c*weighth,weightz,weightz_2)

    #M=c(xdf$M*weighth,hi*weight.c*weighth,hi*weight.c*weighth,weightz,weightz)


    pseudo<-list(X=X,
                 Z_1=Z,
                 Z_2=Z_2,
                 Y=Y,
                 M=M,
                 grouping_1=grouping1,
                 grouping_2=grouping1_2,
                 nn=nn
    )

    if (fit.TMB==FALSE){
      gmm.fit<-glmer(cbind(Y,nn-Y)~-1+X+(-1+Z_1|grouping_1)+(-1+Z_2|grouping_2), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer,check.nobs.vs.nlev ="ignore",check.nlev.gtr.1="ignore",check.nobs.vs.nRE="ignore",check.response.not.const ="ignore") )
      tol2<-max(c(max(abs(fixef(gmm.fit0)-fixef(gmm.fit))),
                  max(abs(ranef(gmm.fit0)$grouping[1:N,]-ranef(gmm.fit)$grouping[1:N,])),
                  max(abs(ranef(gmm.fit0)$grouping_2[1:N,]-ranef(gmm.fit)$grouping_2[1:N,]))))


    } else {
      gmm.fit<-glmmTMB(cbind(Y,nn-Y)~-1+X++(-1+Z_1|grouping_1)+(-1+Z_2|grouping_2), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML)

      tol2<-max(c(max(abs(fixef(gmm.fit0)$cond-fixef(gmm.fit)$cond)),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping[1:N,]-ranef(gmm.fit)[[1]]$grouping[1:N,])),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping_2[1:N,]-ranef(gmm.fit)[[1]]$grouping_2[1:N,]))))

    }


    if (tol2<tol) flag=TRUE
  }

  if (fit.TMB==FALSE){
    cfs[[nIter+1]]<-fixef(gmm.fit)
  } else {
    cfs[[nIter+1]]<-fixef(gmm.fit)$cond
  }

  if (plot.coef.path==TRUE){
    pp<-length(cfs[[1]])
    ce<-matrix(unlist(cfs),byrow=TRUE,ncol=pp)
    par(mfrow=c(1,pp))
    for (i in 1:pp){
      plot(ce[,i],type="l")
    }

  }


  gmm.fit

}


###########

#####allow 3 REs


pen_both_3res<-function(data,psevdo_data_Z,psevdo_data_Z_2,psevdo_data_Z_3,weight.c=1/2,allglmm=FALSE,weight.z=1,tol=1e-6,maxIter=25,penX=TRUE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=FALSE,nAGQ=1,optimizer=c("bobyqa", "Nelder_Mead")){

  # if (is.null(weightz)) weightz<-rep(1,length(psevdo_data_Z$data$Y))

  weightz<-rep(1,length(psevdo_data_Z$data$Y))*weight.z
  weightz_2<-rep(1,length(psevdo_data_Z_2$data$Y))*weight.z
  weightz_3<-rep(1,length(psevdo_data_Z_3$data$Y))*weight.z
  #weighth<-psevdo_data_Z$data$nn[1] #using this makes no sense at all, we get very weird results also for fixef!
  weighth<-1
  xdf=data
  N<-length(unique(xdf$grouping))
  Ntot<-nrow(xdf$X)
  ##here the iterative procedure starts:
  if(penX==TRUE){

    pi0<-rep(0.5,Ntot)
    W<-diag(pi0*(1-pi0))
    #H<- xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
    H<- xdf$X%*%ginv(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
    hi<-diag(H)

  } else {
    hi<-rep(0,Ntot)
  }

  ##add pseudoobsr:
  cfs<-list()


  flag=FALSE

  nIter<-0
  while(flag==FALSE&nIter<maxIter){
    nIter<-nIter+1

    ##add pseudoobsr:

    if (nIter==1) {

      X=rbind(xdf$X,xdf$X,xdf$X,matrix(0,ncol=ncol(xdf$X),
                                       nrow=nrow(psevdo_data_Z$data$Z)+nrow(psevdo_data_Z_2$data$Z)+nrow(psevdo_data_Z_3$data$Z)))

      ZZ=rbind(xdf$Z,matrix(0,ncol=ncol(xdf$Z),nrow=Ntot*2)) #no penalty on Z
      ZZ2=rbind(xdf$Z_2,matrix(0,ncol=ncol(xdf$Z_2),nrow=Ntot*2)) #no penalty on Z2
      ZZ3=rbind(xdf$Z_3,matrix(0,ncol=ncol(xdf$Z_3),nrow=Ntot*2))


      ZZ_1=matrix(0,ncol=ncol(psevdo_data_Z$data$Z),nrow=nrow((psevdo_data_Z_2$data$Z))+nrow((psevdo_data_Z_3$data$Z)))
      ZZ_2=matrix(0,ncol=ncol(psevdo_data_Z_2$data$Z),nrow=nrow((psevdo_data_Z$data$Z))+nrow((psevdo_data_Z_3$data$Z)))
      ZZ_3=matrix(0,ncol=ncol(psevdo_data_Z_3$data$Z),nrow=nrow((psevdo_data_Z$data$Z))+nrow((psevdo_data_Z_2$data$Z)))


      Z=rbind(ZZ,psevdo_data_Z$data$Z,ZZ_1)
      Z_2=rbind(ZZ2,ZZ_2,psevdo_data_Z_2$data$Z)
      Z_3=rbind(ZZ3,ZZ_3,psevdo_data_Z_3$data$Z)


      Y=c(xdf$Y,xdf$Y,1-xdf$Y,psevdo_data_Z$data$Y,psevdo_data_Z_2$data$Y,psevdo_data_Z_3$data$Y)
      M=c(xdf$M*weighth,hi*weight.c*weighth,hi*weight.c*weighth,weightz,weightz_2,weightz_3)
      nn=c(rep(1,nrow(ZZ)),psevdo_data_Z$data$nn,psevdo_data_Z_2$data$nn,psevdo_data_Z_3$data$nn)

      groupingi=c(xdf$grouping,
                  seq(from=1+max(xdf$grouping),by=1,length.out = 2*Ntot)  )
      grouping=c(groupingi,psevdo_data_Z$data$grouping+max(groupingi))
      grouping1=c(grouping,psevdo_data_Z_2$data$grouping+max(grouping))
      grouping1=c(grouping1,psevdo_data_Z_3$data$grouping+max(grouping1))



      groupingi_2=c(xdf$grouping_2,
                    seq(from=1+max(xdf$grouping_2),by=1,length.out = 2*Ntot)  )
      grouping_2=c(groupingi_2,psevdo_data_Z$data$grouping+max(groupingi_2))
      grouping1_2=c(grouping_2,psevdo_data_Z_2$data$grouping+max(grouping_2))
      grouping1_2=c(grouping1_2,psevdo_data_Z_3$data$grouping+max(grouping1_2))


      groupingi_3=c(xdf$grouping_3,
                    seq(from=1+max(xdf$grouping_3),by=1,length.out = 2*Ntot)  )
      grouping_3=c(groupingi_3,psevdo_data_Z$data$grouping+max(groupingi_3))
      grouping1_3=c(grouping_3,psevdo_data_Z_2$data$grouping+max(grouping_3))
      grouping1_3=c(grouping1_3,psevdo_data_Z_3$data$grouping+max(grouping1_3))


      #grouping=rep(xdf$grouping,3) #old version, the new makes more sense (although the res are similar)


      pseudo<-list(X=X,
                   Z_1=Z,
                   Z_2=Z_2,
                   Z_3=Z_3,
                   Y=Y,
                   M=M,
                   grouping_1=grouping1,
                   grouping_2=grouping1_2,
                   grouping_3=grouping1_3,
                   nn=nn
      )


      if (fit.TMB==FALSE){
        gmm.fit0<-glmer(cbind(Y,nn-Y)~-1+X+(-1+Z_1|grouping_1)+(-1+Z_2|grouping_2)+(-1+Z_3|grouping_3), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer,check.nobs.vs.nlev ="ignore",check.nlev.gtr.1="ignore",check.nobs.vs.nRE="ignore",check.response.not.const ="ignore") )
      } else {
        gmm.fit0<-glmmTMB(cbind(Y,nn-Y)~-1+X+(-1+Z_1|grouping_1)+(-1+Z_2|grouping_2)+(-1+Z_3|grouping_3), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML)
      }
    } else {
      gmm.fit0<-gmm.fit
    }
    if (fit.TMB==FALSE){
      cfs[[nIter]]<-fixef(gmm.fit0)
    } else {
      cfs[[nIter]]<-fixef(gmm.fit0)$cond
    }
    #xdf$lp<-predict(gmm.fit0,random.only=TRUE)[1:nrow(xdf$X)]
    #xdf$lp<-get.re(gmm.fit0,nrow(xdf$X),xdf$grouping,xdf$Z)

    if(penX==TRUE){

      if (fit.TMB==FALSE){
        if (allglmm==FALSE){
          pi0<-predict(gmm.fit0,re.form = NA)[1:Ntot]} else {
            pi0<-predict(gmm.fit0)[1:Ntot]
          }
      } else {
        #pi0<-predict(gmm.fit0,newdata=xdf,re.form = NA)
        if (allglmm==TRUE){
          pi0<-c(predict(gmm.fit0,newdata=xdf))} else {
            pi0<-c(xdf$X%*%matrix(fixef(gmm.fit0)$cond,ncol=1))
          }

      }
      pi0<-expit(pi0)
      W<-diag(pi0*(1-pi0))
      #H<-xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
      H<-xdf$X%*%ginv(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
      hi<-diag(H)

    } else {
      hi<-rep(0,Ntot)
    }



    M=c(xdf$M*weighth,hi*weight.c*weighth,hi*weight.c*weighth,weightz,weightz_2,weightz_3)


    pseudo<-list(X=X,
                 Z_1=Z,
                 Z_2=Z_2,
                 Z_3=Z_3,
                 Y=Y,
                 M=M,
                 grouping_1=grouping1,
                 grouping_2=grouping1_2,
                 grouping_3=grouping1_3,
                 nn=nn
    )

    if (fit.TMB==FALSE){
      gmm.fit<-glmer(cbind(Y,nn-Y)~-1+X+(-1+Z_1|grouping_1)+(-1+Z_2|grouping_2)+(-1+Z_3|grouping_3), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer,check.nobs.vs.nlev ="ignore",check.nlev.gtr.1="ignore",check.nobs.vs.nRE="ignore",check.response.not.const ="ignore") )
      tol2<-max(c(max(abs(fixef(gmm.fit0)-fixef(gmm.fit))),
                  max(abs(ranef(gmm.fit0)$grouping[1:N,]-ranef(gmm.fit)$grouping[1:N,])),
                  max(abs(ranef(gmm.fit0)$grouping_2[1:N,]-ranef(gmm.fit)$grouping_2[1:N,])),

                  max(abs(ranef(gmm.fit0)$grouping_3[1:N,]-ranef(gmm.fit)$grouping_3[1:N,]))
                  ))


    } else {
      gmm.fit<-glmmTMB(cbind(Y,nn-Y)~-1+X++(-1+Z_1|grouping_1)+(-1+Z_2|grouping_2)+(-1+Z_3|grouping_3), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML)

      tol2<-max(c(max(abs(fixef(gmm.fit0)$cond-fixef(gmm.fit)$cond)),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping[1:N,]-ranef(gmm.fit)[[1]]$grouping[1:N,])),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping_2[1:N,]-ranef(gmm.fit)[[1]]$grouping_2[1:N,])),

                  max(abs(ranef(gmm.fit0)[[1]]$grouping_3[1:N,]-ranef(gmm.fit)[[1]]$grouping_3[1:N,]))
                  ))

    }


    if (tol2<tol) flag=TRUE
  }

  if (fit.TMB==FALSE){
    cfs[[nIter+1]]<-fixef(gmm.fit)
  } else {
    cfs[[nIter+1]]<-fixef(gmm.fit)$cond
  }

  if (plot.coef.path==TRUE){
    pp<-length(cfs[[1]])
    ce<-matrix(unlist(cfs),byrow=TRUE,ncol=pp)
    par(mfrow=c(1,pp))
    for (i in 1:pp){
      plot(ce[,i],type="l")
    }

  }


  gmm.fit

}





#####allow 4 REs


pen_both_4res<-function(data,psevdo_data_Z,psevdo_data_Z_2,psevdo_data_Z_3,psevdo_data_Z_4,weight.c=1/2,allglmm=FALSE,weight.z=1,tol=1e-6,maxIter=25,penX=TRUE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=FALSE,nAGQ=1,optimizer=c("bobyqa", "Nelder_Mead")){

  # if (is.null(weightz)) weightz<-rep(1,length(psevdo_data_Z$data$Y))

  weightz<-rep(1,length(psevdo_data_Z$data$Y))*weight.z
  weightz_2<-rep(1,length(psevdo_data_Z_2$data$Y))*weight.z
  weightz_3<-rep(1,length(psevdo_data_Z_3$data$Y))*weight.z
  weightz_4<-rep(1,length(psevdo_data_Z_4$data$Y))*weight.z
  #weighth<-psevdo_data_Z$data$nn[1] #using this makes no sense at all, we get very weird results also for fixef!
  weighth<-1
  xdf=data
  N<-length(unique(xdf$grouping))
  Ntot<-nrow(xdf$X)
  ##here the iterative procedure starts:
  if(penX==TRUE){

    pi0<-rep(0.5,Ntot)
    W<-diag(pi0*(1-pi0))
    #H<- xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
    H<- xdf$X%*%ginv(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
    hi<-diag(H)

  } else {
    hi<-rep(0,Ntot)
  }

  ##add pseudoobsr:
  cfs<-list()


  flag=FALSE

  nIter<-0
  while(flag==FALSE&nIter<maxIter){
    nIter<-nIter+1

    ##add pseudoobsr:

    if (nIter==1) {

      X=rbind(xdf$X,xdf$X,xdf$X,matrix(0,ncol=ncol(xdf$X),
                                       nrow=nrow(psevdo_data_Z$data$Z)+nrow(psevdo_data_Z_2$data$Z)+nrow(psevdo_data_Z_3$data$Z)+nrow(psevdo_data_Z_4$data$Z)))

      ZZ=rbind(xdf$Z,matrix(0,ncol=ncol(xdf$Z),nrow=Ntot*2)) #no penalty on Z
      ZZ2=rbind(xdf$Z_2,matrix(0,ncol=ncol(xdf$Z_2),nrow=Ntot*2)) #no penalty on Z2
      ZZ3=rbind(xdf$Z_3,matrix(0,ncol=ncol(xdf$Z_3),nrow=Ntot*2))
      ZZ4=rbind(xdf$Z_4,matrix(0,ncol=ncol(xdf$Z_4),nrow=Ntot*2))

      ZZ_1=matrix(0,ncol=ncol(psevdo_data_Z$data$Z),nrow=nrow((psevdo_data_Z_2$data$Z))+nrow((psevdo_data_Z_3$data$Z))+nrow((psevdo_data_Z_4$data$Z)))
      ZZ_2=matrix(0,ncol=ncol(psevdo_data_Z_2$data$Z),nrow=nrow((psevdo_data_Z$data$Z))+nrow((psevdo_data_Z_3$data$Z))+nrow((psevdo_data_Z_4$data$Z)))
      ZZ_3=matrix(0,ncol=ncol(psevdo_data_Z_3$data$Z),nrow=nrow((psevdo_data_Z$data$Z))+nrow((psevdo_data_Z_2$data$Z))+nrow((psevdo_data_Z_4$data$Z)))

      ZZ_4=matrix(0,ncol=ncol(psevdo_data_Z_4$data$Z),nrow=nrow((psevdo_data_Z$data$Z))+nrow((psevdo_data_Z_2$data$Z))+nrow((psevdo_data_Z_3$data$Z)))


      Z=rbind(ZZ,psevdo_data_Z$data$Z,ZZ_1)
      Z_2=rbind(ZZ2,ZZ_2,psevdo_data_Z_2$data$Z)
      Z_3=rbind(ZZ3,ZZ_3,psevdo_data_Z_3$data$Z)
      Z_4=rbind(ZZ4,ZZ_4,psevdo_data_Z_4$data$Z)


      Y=c(xdf$Y,xdf$Y,1-xdf$Y,psevdo_data_Z$data$Y,psevdo_data_Z_2$data$Y,psevdo_data_Z_3$data$Y,psevdo_data_Z_4$data$Y)
      M=c(xdf$M*weighth,hi*weight.c*weighth,hi*weight.c*weighth,weightz,weightz_2,weightz_3,weightz_4)
      nn=c(rep(1,nrow(ZZ)),psevdo_data_Z$data$nn,psevdo_data_Z_2$data$nn,psevdo_data_Z_3$data$nn,psevdo_data_Z_4$data$nn)

      groupingi=c(xdf$grouping,
                  seq(from=1+max(xdf$grouping),by=1,length.out = 2*Ntot)  )
      grouping=c(groupingi,psevdo_data_Z$data$grouping+max(groupingi))
      grouping1=c(grouping,psevdo_data_Z_2$data$grouping+max(grouping))
      grouping1=c(grouping1,psevdo_data_Z_3$data$grouping+max(grouping1))
      grouping1=c(grouping1,psevdo_data_Z_4$data$grouping+max(grouping1))


      groupingi_2=c(xdf$grouping_2,
                    seq(from=1+max(xdf$grouping_2),by=1,length.out = 2*Ntot)  )
      grouping_2=c(groupingi_2,psevdo_data_Z$data$grouping+max(groupingi_2))
      grouping1_2=c(grouping_2,psevdo_data_Z_2$data$grouping+max(grouping_2))
      grouping1_2=c(grouping1_2,psevdo_data_Z_3$data$grouping+max(grouping1_2))
      grouping1_2=c(grouping1_2,psevdo_data_Z_4$data$grouping+max(grouping1_2))

      groupingi_3=c(xdf$grouping_3,
                    seq(from=1+max(xdf$grouping_3),by=1,length.out = 2*Ntot)  )
      grouping_3=c(groupingi_3,psevdo_data_Z$data$grouping+max(groupingi_3))
      grouping1_3=c(grouping_3,psevdo_data_Z_2$data$grouping+max(grouping_3))
      grouping1_3=c(grouping1_3,psevdo_data_Z_3$data$grouping+max(grouping1_3))
      grouping1_3=c(grouping1_3,psevdo_data_Z_4$data$grouping+max(grouping1_3))


      groupingi_4=c(xdf$grouping_4,
                    seq(from=1+max(xdf$grouping_4),by=1,length.out = 2*Ntot)  )
      grouping_4=c(groupingi_4,psevdo_data_Z$data$grouping+max(groupingi_4))
      grouping1_4=c(grouping_4,psevdo_data_Z_2$data$grouping+max(grouping_4))
      grouping1_4=c(grouping1_4,psevdo_data_Z_3$data$grouping+max(grouping1_4))
      grouping1_4=c(grouping1_4,psevdo_data_Z_4$data$grouping+max(grouping1_4))




      #grouping=rep(xdf$grouping,3) #old version, the new makes more sense (although the res are similar)


      pseudo<-list(X=X,
                   Z_1=Z,
                   Z_2=Z_2,
                   Z_3=Z_3,
                   Z_4=Z_4,
                   Y=Y,
                   M=M,
                   grouping_1=grouping1,
                   grouping_2=grouping1_2,
                   grouping_3=grouping1_3,
                   grouping_4=grouping1_4,
                   nn=nn
      )


      if (fit.TMB==FALSE){
        gmm.fit0<-glmer(cbind(Y,nn-Y)~-1+X+(-1+Z_1|grouping_1)+(-1+Z_2|grouping_2)+(-1+Z_3|grouping_3)+(-1+Z_4|grouping_4), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer,check.nobs.vs.nlev ="ignore",check.nlev.gtr.1="ignore",check.nobs.vs.nRE="ignore",check.response.not.const ="ignore") )
      } else {
        gmm.fit0<-glmmTMB(cbind(Y,nn-Y)~-1+X+(-1+Z_1|grouping_1)+(-1+Z_2|grouping_2)+(-1+Z_3|grouping_3)+(-1+Z_4|grouping_4), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML)
      }
    } else {
      gmm.fit0<-gmm.fit
    }
    if (fit.TMB==FALSE){
      cfs[[nIter]]<-fixef(gmm.fit0)
    } else {
      cfs[[nIter]]<-fixef(gmm.fit0)$cond
    }
    #xdf$lp<-predict(gmm.fit0,random.only=TRUE)[1:nrow(xdf$X)]
    #xdf$lp<-get.re(gmm.fit0,nrow(xdf$X),xdf$grouping,xdf$Z)

    if(penX==TRUE){

      if (fit.TMB==FALSE){
        if (allglmm==FALSE){
          pi0<-predict(gmm.fit0,re.form = NA)[1:Ntot]} else {
            pi0<-predict(gmm.fit0)[1:Ntot]
          }
      } else {
        #pi0<-predict(gmm.fit0,newdata=xdf,re.form = NA)
        if (allglmm==TRUE){
          pi0<-c(predict(gmm.fit0,newdata=xdf))} else {
            pi0<-c(xdf$X%*%matrix(fixef(gmm.fit0)$cond,ncol=1))
          }

      }
      pi0<-expit(pi0)
      W<-diag(pi0*(1-pi0))
      #H<-xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
      H<-xdf$X%*%ginv(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
      hi<-diag(H)

    } else {
      hi<-rep(0,Ntot)
    }



    M=c(xdf$M*weighth,hi*weight.c*weighth,hi*weight.c*weighth,weightz,weightz_2,weightz_3,weightz_4)


    pseudo<-list(X=X,
                 Z_1=Z,
                 Z_2=Z_2,
                 Z_3=Z_3,
                 Z_4=Z_4,
                 Y=Y,
                 M=M,
                 grouping_1=grouping1,
                 grouping_2=grouping1_2,
                 grouping_3=grouping1_3,
                 grouping_4=grouping1_4,
                 nn=nn
    )

    if (fit.TMB==FALSE){
      gmm.fit<-glmer(cbind(Y,nn-Y)~-1+X+(-1+Z_1|grouping_1)+(-1+Z_2|grouping_2)+(-1+Z_3|grouping_3)+(-1+Z_4|grouping_4), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer,check.nobs.vs.nlev ="ignore",check.nlev.gtr.1="ignore",check.nobs.vs.nRE="ignore",check.response.not.const ="ignore") )
      tol2<-max(c(max(abs(fixef(gmm.fit0)-fixef(gmm.fit))),
                  max(abs(ranef(gmm.fit0)$grouping[1:N,]-ranef(gmm.fit)$grouping[1:N,])),
                  max(abs(ranef(gmm.fit0)$grouping_2[1:N,]-ranef(gmm.fit)$grouping_2[1:N,])),
                  max(abs(ranef(gmm.fit0)$grouping_3[1:N,]-ranef(gmm.fit)$grouping_3[1:N,])),
                  max(abs(ranef(gmm.fit0)$grouping_4[1:N,]-ranef(gmm.fit)$grouping_4[1:N,]))

                  ))


    } else {
      gmm.fit<-glmmTMB(cbind(Y,nn-Y)~-1+X++(-1+Z_1|grouping_1)+(-1+Z_2|grouping_2)+(-1+Z_3|grouping_3)+(-1+Z_4|grouping_4), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML)

      tol2<-max(c(max(abs(fixef(gmm.fit0)$cond-fixef(gmm.fit)$cond)),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping[1:N,]-ranef(gmm.fit)[[1]]$grouping[1:N,])),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping_2[1:N,]-ranef(gmm.fit)[[1]]$grouping_2[1:N,])),

                  max(abs(ranef(gmm.fit0)[[1]]$grouping_3[1:N,]-ranef(gmm.fit)[[1]]$grouping_3[1:N,])),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping_4[1:N,]-ranef(gmm.fit)[[1]]$grouping_4[1:N,]))
                  ))

    }


    if (tol2<tol) flag=TRUE
  }

  if (fit.TMB==FALSE){
    cfs[[nIter+1]]<-fixef(gmm.fit)
  } else {
    cfs[[nIter+1]]<-fixef(gmm.fit)$cond
  }

  if (plot.coef.path==TRUE){
    pp<-length(cfs[[1]])
    ce<-matrix(unlist(cfs),byrow=TRUE,ncol=pp)
    par(mfrow=c(1,pp))
    for (i in 1:pp){
      plot(ce[,i],type="l")
    }

  }


  gmm.fit

}






############

pen_onlyZ_kos<-function(data,psevdo_data_Z,weight.z=1,nAGQ=1,penX=TRUE,optimization_methods = c("BFGS", "CG")){

  # if (is.null(weightz)) weightz<-rep(1,length(psevdo_data_Z$data$Y))

  weightz<-rep(1,length(psevdo_data_Z$data$Y))*weight.z
  #weighth<-psevdo_data_Z$data$nn[1] #using this makes no sense at all, we get very weird results also for fixef!
   xdf=data

  p <- ncol(xdf$X)
  q <- max(1, ncol(xdf$Z))
  npar <- p + 0.5 * q * (q + 1)

  start<-rep(0,npar)

  N<-length(unique(xdf$grouping))
  Ntot<-nrow(xdf$X)
  ##here the iterative procedure starts:
  if (penX==TRUE) wx<-2*sqrt(p/Ntot) else wx<-0

  ##add pseudoobsr:




      X=rbind(xdf$X,matrix(0,ncol=ncol(xdf$X),nrow=nrow(psevdo_data_Z$data$Z)))


      Z=rbind(xdf$Z,psevdo_data_Z$data$Z)
      Y=c(xdf$Y,psevdo_data_Z$data$Y)
      M=c(xdf$M,weightz)
      nn=c(rep(1,nrow(xdf$Z)),psevdo_data_Z$data$nn)
      groupingi=c(xdf$grouping  )
      grouping=c(groupingi,psevdo_data_Z$data$grouping+max(groupingi))
      #grouping=rep(xdf$grouping,3) #old version, the new makes more sense (although the res are similar)


      pseudo<-list(X=X,
                   Z=Z,
                   Y=Y,
                   M=M,
                   grouping=grouping,
                   nn=nn
      )


      gmm.fit<- mv_get_MSPAL(start, data=pseudo, nAGQ =nAGQ ,
                              mult = c(wx,0), pen_log_sigma = NULL,
                              optimization_methods = optimization_methods,
                              method_suffix = "", method_name = NULL)





  gmm.fit

}


#aux function to get D for Kosmidis parametrization

getsigma<-function(x,p){
  L<-rbind(c(exp(x[p+1,1]),0),
           c(x[p+2,1],exp(x[p+3,1])))
  L%*%t(L)
}


###penalty function to be used for Kos fnctns
#x - vector of variance parameters: the nonzero elements of L going from colmn1 to colmnq
#the first q elements need to be diags of the chol, the others are the off diags

#diag - numeric, indicates the position of diag elemements in x
rok_penalty<-function(x,nu,psi){
 q<-nrow(psi)
 inds <- vapply(1:q, function(i) {2 + (q + 2) * (i - 1) - i * (i + 1) / 2}, 1)

  l.diag<-x[inds]
  exp.l.diag<-exp(l.diag)
  #make matrix L.tilde
  L.tilde<-diag(exp.l.diag)
  zz=0
  for (i in 2:q){
    for (j in 1:(i-1)){
      zz=zz+1
      L.tilde[i,j]<-x[q+zz]
    }
  }

  sum((-nu-(1:q)+1)*l.diag)-1/2*sum(diag(  solve(psi)%*%solve( L.tilde%*%t(L.tilde)  )   ))
}

#example
nu=4
psi=rbind(c(2,0.1,0.3),c(0.1,1,0.4),c(0.3,0.4,3))
library(clusterGeneration)
D<-genPositiveDefMat(nrow(psi))$Sigma

L<-t(chol(D))
x<-L[lower.tri(L,diag=TRUE)]


rok_penalty(x=x,nu=4,psi=psi)





######linear



#here const should play no role!

make_pseudo_data_rand_eigen_general_psi_lmm<-function(psi,nu,alpha,beta,const=1e6){

  q<-ncol(psi)
    cc<-(nu-q-1)/q


  cc<-max(c(floor(cc),1))
   true<-solve(psi)/cc#*sigma2
    ee<-eigen(true,TRUE)
  yi<-list()
  for (j in 1:q){
    yi[[j]]<-sqrt(ee$values[j])*ee$vectors[,j]
  }

  Y<- unlist(yi)

  #id<-c(1,1,2,2)
  id<-rep(1:q,each=q)

  Zi<-matrix(0,ncol=q,nrow=q)

  for (j in 1:q){
    Zi[j,j]<-1
  }
  for (j in 1:q){
    if (j==1) Z=Zi else Z<-rbind(Z,Zi)
  }
  fact<-cc
  if (fact>1){
    Y<-rep(Y,fact)
     id<-rep(1:(q*fact),each=q)
    for (j in 1:(q*fact)){
      if (j==1) Z=Zi else Z<-rbind(Z,Zi)
    }
  }
  w<-rep(const,length(Y))
  #M<-rep(1/q,length(Y))
  #Z<-rbind(c(1,0),c(1,1),c(1,0),c(1,1))
  #data0<-list(Y=Y,grouping=id,nn=n,Z=Z,M=M)
  data0<-list(Y=Y,grouping=id, Z=Z,w=w)

  #Y<-c(sqrt(sigma2),sqrt(sigma2))
  #Z<-matrix(0,ncol=q,nrow=2)
  #id<-rep(max(id)+1,2)
  #data1<-list(Y=Y,grouping=id, Z=Z,w=rep(1,2))

  NN<-floor(2*alpha-2)
  Y<-rep(sqrt(2*beta/NN),NN)
  Z<-matrix(0,ncol=q,nrow=NN)
  id<-seq(from=max(id)+1,by=1,length.out = NN)
  data1<-list(Y=Y,grouping=id, Z=Z,w=rep(1,NN))
  #data1<-list(Y=Y,grouping=id, Z=Z,w=rep(const,NN)) #we should not do this!



  Y<-c(data0$Y,data1$Y)
  id<-c(data0$grouping,data1$grouping)
  Z<-rbind(data0$Z,data1$Z)
  w<-c(data0$w,data1$w)
  data01<-list(Y=Y,grouping=id, Z=Z,w=w)

  #fit0<-glmmTMB(Y~-1+(-1+Z|grouping),data=data1)
  #fit0<-glmmTMB(Y~-1+(-1+Z|grouping),weights=w,data=data0)
  #fit0<-glmmTMB(Y~-1+(-1+Z|grouping),data=data01)

  fit0<-lmer(Y~-1+(-1+Z|grouping),data=data01,weights=w,REML=FALSE,control=lmerControl(check.nobs.vs.nlev ="ignore",
  check.nlev.gtr.1 ="ignore",check.nobs.vs.nRE="ignore"))
  est.D<-VarCorr(fit0)$grouping[1:q,1:q]
  est.vr<-attributes(VarCorr(fit0))$sc

  list(data=data01,fit=fit0,vcv.re=est.D,sd.eps=est.vr)
}

psi<-rbind(c(1,-0),c(0,1))
nu=13
alpha=3
beta=1

sigma2<-beta/(alpha-1)


d1<-make_pseudo_data_rand_eigen_general_psi_lmm(psi,nu,alpha,beta,const=1e6)
#note that the estimate of D- obtained only on pseudo
solve(d1$vcv.re)
#is the same as the mode of W
psi*(nu-2-1)

sigma2
d1$sd.eps**2


#due to relation between W and IW the MLE of D
d1$vcv.re
#also corresponds to the mean of IW
solve(psi)/(nu-2-1)



1/(d1$sd.eps**2)
(alpha-1)/beta


d11<-d1$data
d11$Y<-d11$Y[d11$grouping<11]
d11$w<-d11$w[d11$grouping<11]
d11$Z<-d11$Z[d11$grouping<11,]
d11$grouping<-d11$grouping[d11$grouping<11]

fit0<-lmer(Y~-1+(-1+Z|grouping),data=d11,weights=w,REML=FALSE,control=lmerControl(check.nobs.vs.nlev ="ignore",
                                                                                  check.nlev.gtr.1 ="ignore",check.nobs.vs.nRE="ignore"))



sim.data.cluster<-function(N,n,betas, norm.eps,var.eps=NULL,shape=NULL,scale=NULL,norm.re.intercept,var.re.intercept=NULL,shape.re.intercept=NULL,scale.re.intercept=NULL,sim.re.slope,
                           norm.re.slope=NULL,var.re.slope=NULL,shape.re.slope=NULL,scale.re.slope=NULL,sim.x2.qdr=FALSE,b.qdr=NULL){



  yy<-NA

  id<-NA
  x1<-NA
  x2<-NA
  for (gg in 1:N){

    id<-c(id,rep(gg,each=n[gg]))
    x11<-runif(n[gg])
    x1<-c(x1,x11)

    x22<-runif(n[gg])
    x2<-c(x2,x22)
    if (norm.re.intercept==TRUE) re.int<-rnorm(1,sd=sqrt(var.re.intercept)) else re.int<-rgamma(1,shape=shape.re.intercept,scale=scale.re.intercept)-shape.re.intercept*scale.re.intercept

    b<-rep(re.int,each=n[gg])



    if (norm.eps==TRUE) eps<-rnorm(n[gg],sd=sqrt(var.eps)) else eps<-rgamma(n[gg],shape=shape,scale=scale)-shape*scale

    if (sim.re.slope==TRUE) {
      if (norm.re.slope==TRUE) re.slope<-rnorm(1,sd=sqrt(var.re.slope)) else re.slope<-rgamma(1,shape=shape.re.slope,scale=scale.re.slope)-shape.re.slope*scale.re.slope

      b2<-rep(re.slope,each=n[gg])

      if (sim.x2.qdr==FALSE)   y<-betas[1]+betas[2]*x11+betas[3]*x22+b+b2*x11+eps  else y<-betas[1]+betas[2]*x11+betas[3]*x22+b+b2*x11+eps+ b.qdr*x11**2
    } else {
      if (sim.x2.qdr==FALSE) y<-betas[1]+betas[2]*x11+betas[3]*x22+b+eps   else y<-betas[1]+betas[2]*x11+betas[3]*x22+b+eps+ b.qdr*x11**2

    }
    yy<-c(yy,y)

  }
  yy<-yy[-1]
  x2<-x2[-1]
  x1<-x1[-1]
  id<-id[-1]
  df<-data.frame(id=id,y=yy,x1=x1,x2=x2)

  df

}

dd<-sim.data.cluster(N=20,n=rep(4,20),betas=c(1,0.3,0.5), norm.eps=TRUE,var.eps=0.5,shape=NULL,scale=NULL,
                     norm.re.intercept=TRUE,var.re.intercept=0.25,shape.re.intercept=NULL,scale.re.intercept=NULL,sim.re.slope=TRUE,
                               norm.re.slope=TRUE,var.re.slope=0.05,shape.re.slope=NULL,scale.re.slope=NULL,sim.x2.qdr=FALSE,b.qdr=NULL)

xdf<-list()
xdf$X<-cbind(1,dd$x1,dd$x2)
xdf$Z<-cbind(1,dd$x1)
xdf$grouping<-dd$id
xdf$Y<-dd$y
xdf$M<-rep(1,length(xdf$Y))
fit0<-lmer(Y~-1+X+(-1+Z|grouping),data=xdf,REML=FALSE)



psi<-rbind(c(1,0),c(0,1))
nu=5
alpha=3
beta=1

sigma2<-beta/(alpha-1)


d1<-make_pseudo_data_rand_eigen_general_psi_lmm(psi,nu,alpha,beta,const=1e8)

pseudo<-list()
pseudo$X<-rbind(xdf$X,matrix(0,nrow(d1$data$Z),ncol(xdf$X)))
pseudo$Z<-rbind(xdf$Z,d1$data$Z)
pseudo$Y<-c(xdf$Y,d1$data$Y)
pseudo$grouping<-c(xdf$grouping,max(xdf$grouping)+d1$data$grouping)
pseudo$M<-c(xdf$M,d1$data$w)

fit1<-lmer(Y~-1+X+(-1+Z|grouping),weights = M,data=pseudo,REML=FALSE)


VarCorr(fit0)$grouping[1:2,1:2]
VarCorr(fit1)$grouping[1:2,1:2]
d1$vcv.re




#############nonlinear





make_pseudo_data_rand_eigen_general_psi_v3_glmm<-function(psi,nu,const=1e8,param="precision",link_fun=function(x) 1/(1+exp(-x))){
  if (is.null(match.arg(param,c("precision","variance")))) stop("param needs to be one of: precision,variance")

  q<-ncol(psi)
  if (param=="precision") cc<-(nu-q-1)/q
  if (param=="variance") cc<-(nu+q+1)/q

  cc<-max(c(floor(cc),1))
  if (param=="precision") true<-solve(psi)/cc
  if (param=="variance") true<-psi/cc
  ee<-eigen(true,TRUE)
  ui<-list()
  for (j in 1:q){
    ui[[j]]<-sqrt(ee$values[j])*ee$vectors[,j]
  }

  #u1<-sqrt(ee$values[1])*ee$vectors[,1]
  #u2<-sqrt(ee$values[2])*ee$vectors[,2]

  #matrix(u1,ncol=1)%*%matrix(u1,nrow=1)+matrix(u2,ncol=1)%*%matrix(u2,nrow=1)
  pi<-list()

  for (j in 1:length(ui)){
    I<-diag(rep(1,length(ui[[j]])))
    #pi[[j]]<-1/(1+exp(-I%*%matrix(ui[[j]],ncol=1)))
    pi[[j]]<-link_fun(I%*%matrix(ui[[j]],ncol=1))
  }
  #pi0=exp(u1[1])/(1+exp(u1[1]))
  #pi1=exp(u1[2])/((1-pi0)/pi0+exp(u1[2]))

  #pi02=exp(u2[1])/(1+exp(u2[1]))
  #pi12=exp(u2[2])/((1-pi02)/pi02+exp(u2[2]))


  #Y<-c(pi0,pi1,pi02,pi12)*1e8 #the constant improves the convergence!
  Y<-unlist(pi)

  #id<-c(1,1,2,2)
  id<-rep(1:q,each=q)
  n<-rep(const,length(id))

  Zi<-matrix(0,ncol=q,nrow=q)

  for (j in 1:q){
    Zi[j,j]<-1
  }
  for (j in 1:q){
    if (j==1) Z=Zi else Z<-rbind(Z,Zi)
  }

  fact<-cc
  if (fact>1){
    Y<-rep(Y,fact)
    n<-rep(n,fact)
    id<-rep(1:(q*fact),each=q)
    for (j in 1:(q*fact)){
      if (j==1) Z=Zi else Z<-rbind(Z,Zi)
    }
  }

  #M<-rep(1/q,length(Y))
  #Z<-rbind(c(1,0),c(1,1),c(1,0),c(1,1))
  #data0<-list(Y=Y,grouping=id,nn=n,Z=Z,M=M)
  data0<-list(Y=Y,grouping=id,nn=n,Z=Z)

  #fit0<-glmmTMB(cbind(Y,nn-Y)~-1+(-1+Z|grouping),weights=M,data=data0,family=binomial)
  #fit0<-glmmTMB(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=data0,family=binomial)
  #est.vcv<-VarCorr(fit0)$cond$grouping[1:q,1:q]

  list(data=data0)#,fit=fit0,vcv.re=est.vcv)
}




fm1 <- nlme(height ~ SSasymp(age, Asym, R0, lrc),
            data = Loblolly,
            fixed = Asym + R0 + lrc ~ 1,
            random = Asym ~ 1,
            start = c(Asym = 103, R0 = -8.5, lrc = -3.3))




















