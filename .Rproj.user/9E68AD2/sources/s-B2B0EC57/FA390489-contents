library(lme4)
library(mvtnorm)
library(glmmTMB)

library(numDeriv)
library(blme)
library(xtable)
library(patchwork)
library(scales)
library(cowplot)
library(ggplot2)
library(memisc)
library(dplyr)

library(optimx)
library(brms)

library(rstan)


source("source_script.R")



#generate data for rand slope and rand intercept (potentially correlated)
make.data<-function(n,N,p,beta,b0,x.type="bernouli1",x.prob=0.3,var.random.inter=0.4,var.random.slope=0.2,cov.re=0.2){
  sigma<-matrix(c(var.random.inter,cov.re,cov.re,var.random.slope),ncol=2)
  
  if (p==1) formX<-formula(~V1)
  if (p==2) formX<-formula(~V1+V2)
  if (p==3) formX<-formula(~V1+V2+V3)
  if (p==4) formX<-formula(~V1+V2+V3+V4)
  if (p==5) formX<-formula(~V1+V2+V3+V4+V5)
  
  flg<-TRUE
  while(flg==TRUE){
    #generate data
    
    x<-matrix(NA,ncol=p,nrow=1)
    y<-NA
    id<-NA
    pii<-trueB<-list()
    for (i in 1:N){
      
      if (x.type=="norm") xi<-matrix(rnorm(n*p),ncol=p)
      if (x.type=="bernouli1") xi<-matrix(rbinom(n*p,prob=x.prob,size=1),ncol=p)
      if (x.type=="bernouli2") xi<-matrix(rep(rbinom(p,prob=x.prob,size=1),each=n),ncol=p)
      
      xm<-cbind(1,xi)
      
      re<-rmvnorm(1, mean = rep(0, nrow(sigma)), sigma = sigma)
      random.intercept<-re[1]
      bi<-re[2]
      
      
      
      betas<-c(random.intercept+b0,beta[1]+bi,beta[-1])
      
      
      trueB[[i]]<-xm[,1:2]%*%matrix(re,ncol=1)
      
      id.i<-rep(i,each=n)
      
      mui<- xm%*%matrix(betas,ncol=1) 
      pi<-1/(1+exp(-mui))
      pii[[i]]<-pi
      y.i<-rbinom(n,size=1,prob=pi)
      
      x<-rbind(x,xi)
      y<-c(y,y.i)
      id<-c(id,id.i)
      
    }
    xdf<-as.data.frame(x)
    nm<-names(xdf)
    if (sum(apply(as.matrix(xdf[-1,1:p],ncol=p,nrow=nrow(xdf)-1),2,sum)==0)==0) flg=FALSE else flg=TRUE
  }
  
  #start analysis
  true.pi<-unlist(pii)
  
  xdf$y<-y
  xdf$id<-id
  
  
  xdf<-xdf[-1,]
  
  data <- list(Y = xdf$y,
               X = model.matrix(
                 formX, data = xdf),
               Z = cbind(
                 rep(1, nrow(xdf)),
                 xdf$V1),
               M = rep(1, nrow(xdf)),
               grouping = xdf$id,
               trueB=unlist(trueB),
               truepi=true.pi)
  
  data
}


##example of use
#xdf<-make.data(10,50,4,c(1,-0.5,0.5,0),-2,var.random.inter=1,var.random.slope=0.6,cov.re=0.2)

#####################################
#####################################


##make psevdo data to implement Inverse-Wishart prior: not general!
###general function for q>1 (note, it does not work for q=1!)
#D0 a pdf matrix 
#fact can be used to control the variance
#const a large positive constant to improve approximation

make_pseudo_data_rand_eigen_general<-function(D0,fact=1,const=1e8){
  q<-nrow(D0)
  true=q*D0
  
  ee<-eigen(true,TRUE)
  ui<-list()
  for (j in 1:q){
    ui[[j]]<-sqrt(ee$values[j])*ee$vectors[,j]
  }
  
  #u1<-sqrt(ee$values[1])*ee$vectors[,1]
  #u2<-sqrt(ee$values[2])*ee$vectors[,2]
  
  #matrix(u1,ncol=1)%*%matrix(u1,nrow=1)+matrix(u2,ncol=1)%*%matrix(u2,nrow=1)
  pi0<-pi1<-list()
  for (j in 1:q){
    pi0[[j]]=exp(ui[[j]][1])/(1+exp(ui[[j]][1]))
    for (jj in 2:q){
      if (jj==2) pi1[[j]]<-exp(ui[[j]][jj])/((1-pi0[[j]])/pi0[[j]]+exp(ui[[j]][jj])) else pi1[[j]]=c(pi1[[j]],exp(ui[[j]][jj])/((1-pi0[[j]])/pi0[[j]]+exp(ui[[j]][jj])))
    }
  }
  #pi0=exp(u1[1])/(1+exp(u1[1]))
  #pi1=exp(u1[2])/((1-pi0)/pi0+exp(u1[2]))
  
  #pi02=exp(u2[1])/(1+exp(u2[1]))
  #pi12=exp(u2[2])/((1-pi02)/pi02+exp(u2[2]))
  
  #Y<-c(pi0,pi1,pi02,pi12)*1e8 #the constant improves the convergence!
  Y<-NA
  for (j in 1:q){
  Y<-c(Y,pi0[[j]],pi1[[j]])
    }
  Y<-Y[-1]
  
  #id<-c(1,1,2,2)
  id<-rep(1:q,each=q)
  n<-rep(const,length(id))
  Y<-Y*const
  
  Zi<-matrix(0,ncol=q,nrow=q)
  Zi[,1]<-1
  for (j in 2:q){
    Zi[j,j]<-1
  }
  for (j in 1:q){
    if (j==1) Z=Zi else Z<-rbind(Z,Zi)
  }
  
  if (fact>1){
    Y<-rep(Y,fact)
    n<-rep(n,fact)
    id<-rep(1:(q*fact),each=q)
    for (j in 1:(q*fact)){
      if (j==1) Z=Zi else Z<-rbind(Z,Zi)
    }
  }
  
  
  #Z<-rbind(c(1,0),c(1,1),c(1,0),c(1,1))
  data0<-list(Y=Y,grouping=id,nn=n,Z=Z)
  
  fit0<-glmer(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=data0,family=binomial)
  est.vcv<-VarCorr(fit0)$grouping[1:q,1:q]
  
  list(data=data0,fit=fit0,vcv.re=est.vcv)
}


#####example of use
k=2
A<-matrix(rnorm(k*k),ncol=k)
exampleD<-A%*%t(A)

make_pseudo_data_rand_eigen_general(exampleD,fact=1)$vcv.re-exampleD

k=3
A<-matrix(rnorm(k*k),ncol=k)
exampleD<-A%*%t(A)

make_pseudo_data_rand_eigen_general(exampleD,fact=1)$vcv.re-exampleD
#seems to work ok



####pseudo data only for random intercept: note you cannot fit lmer only to pseudodata since there is only one cluster, but you can still check by fitting to all and calculating the variance by yourself!

make_pseudo_data_rand_eigen_inter<-function(var.int,fact=1,const=1e8){
  
  true=matrix(var.int,ncol=1,nrow=1)
  
  ee<-eigen(true,TRUE)
  u1<-sqrt(ee$values[1])*ee$vectors[,1]
  #u2<-sqrt(ee$values[2])*ee$vectors[,2]
  
  #matrix(u1,ncol=1)%*%matrix(u1,nrow=1)+matrix(u2,ncol=1)%*%matrix(u2,nrow=1)
  
  
  pi0=exp(u1[1])/(1+exp(u1[1]))
   
  Y<-rep(c(pi0)*const,fact) #the constant improves the convergence!
  n<-rep(rep(const,1),fact)
  id<-c(1:fact)
  Z<-matrix(rep(1,fact),ncol=1)
  data0<-list(Y=Y,grouping=id,nn=n,Z=Z)
  
  #fit0<-glmer(cbind(Y,nn-Y)~-1+(-1+Z|grouping),data=data0,family=binomial)
  #est.vcv<-VarCorr(fit0)$grouping[1:2,1:2]
  
  list(data=data0)#,fit=fit0,vcv.re=est.vcv)
}

###Example of use

make_pseudo_data_rand_eigen_inter(1,fact=10,const=1e8)



#######################

####aux functions


get.re<-function(fit,N,grouping=NULL,Z=NULL){
  if (class(fit)=="glmerMod"){
    lp<-predict(fit,random.only=TRUE)[1:N]
    
  } else {
    blups<-as.matrix(ranef(fit)$cond[[1]]) 
    lp<-rep(NA,nrow(Z))
    for (kk in 1:nrow(blups)){
      lp[  grouping ==rownames(blups)[kk]  ]<-Z[grouping ==rownames(blups)[kk],]%*%matrix(as.numeric(blups[kk,]),ncol=1)
    }
    
  }
  lp
}
"%^%" <- function(x, n)   with(eigen(x), vectors %*% (values^n * t(vectors)))
expit<-function(x) 1/(1+exp(-x))



####this is the implementation of Georg's idea

#data - list with elements Y, X, Z, grouping, M
#penZ - TRUE sets Z for pseudo for X to Z,Z (Georg), FALSE sets them to 0 (Rok)
#fit.TMB TRUE uses glmmTMB, FALSE uses glmer
#REML - only applies if fit.TMB=TRUE, if TRUE uses REML for variance components, if FALSE uses ML
#plot.coef.path - plots coefficient pats for each fixef parameter
#fit.frth - if TRUE it fits firth with offset to get his, otherwise it calculates them from the hat matrix (using the formula for GLM), where the probabilities are based on fixed and REs.
 
#typehat: 1-using x and z to get p, 2-using only X to get p
georg.glmm.general.iter<-function(data,tol=1e-6,maxIter=25,penX=TRUE,penZ=FALSE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=FALSE,fit.frth=TRUE,nAGQ=1,optimizer=c("bobyqa", "Nelder_Mead"),typehat=1){
  
  
  xdf=data
  N<-length(unique(xdf$grouping))
  ##here the iterative procedure starts:
  if(penX==TRUE){
    if (fit.frth==TRUE){
      firth<-logistf(Y~-1+X,data=xdf,pl=FALSE,firth=TRUE)
      hi<-firth$hat.diag
    } else {
      pi0<-rep(0.5,nrow(xdf$X))
      W<-diag(pi0*(1-pi0))
      H<-(W%^%(1/2))%*%xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W%^%(1/2))
      hi<-diag(H)
    }
  } else {
    hi<-rep(0,nrow(xdf$X))
  }
  
  ##add pseudoobsr:
  cfs<-list()
  
  
  flag=FALSE
  
  nIter<-0
  while(flag==FALSE&nIter<maxIter){
    nIter<-nIter+1
    
    ##add pseudoobsr:
    
    if (nIter==1) {
      
      X=rbind(xdf$X,xdf$X,xdf$X)
      if (penZ==FALSE){
        Z=rbind(xdf$Z,matrix(0,ncol=ncol(xdf$Z),nrow=nrow(xdf$Z)*2)) #no penalty on Z
      } else {
        Z=rbind(xdf$Z,xdf$Z,xdf$Z) #georg
      }
      Y=c(xdf$Y,xdf$Y,1-xdf$Y)
      M=c(xdf$M,hi/2,hi/2)
      grouping=c(xdf$grouping,
                 xdf$grouping+max(xdf$grouping),xdf$grouping+2*max(xdf$grouping))
      #grouping=rep(xdf$grouping,3) #old version, the new makes more sense (although the res are similar)
      
      
      pseudo<-list(X=X,
                   Z=Z,
                   Y=Y,
                   M=M,
                   grouping=grouping
      )
      
      
      if (fit.TMB==FALSE){
        gmm.fit0<-glmer(Y~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M ,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer))    
      } else {
        gmm.fit0<-glmmTMB(Y~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML) 
      }
    } else {
      gmm.fit0<-gmm.fit
    }
    if (fit.TMB==FALSE){
      cfs[[nIter]]<-fixef(gmm.fit0)
    } else {
      cfs[[nIter]]<-fixef(gmm.fit0)$cond
    }
    #xdf$lp<-predict(gmm.fit0,random.only=TRUE)[1:nrow(xdf$X)]
    xdf$lp<-get.re(gmm.fit0,nrow(xdf$X),xdf$grouping,xdf$Z)
    
    if(penX==TRUE){
      if (fit.frth==TRUE){
        firth<-logistf(Y~-1+X+offset(lp),data=xdf,pl=FALSE,firth=TRUE)
        hi<-firth$hat.diag
      } else {
        if (fit.TMB==FALSE){
          if (typehat==1) pi0<-predict(gmm.fit0)[1:nrow(xdf$X)] else pi0<-predict(gmm.fit0,re.form = NA)[1:nrow(xdf$X)]
        } else {
          if (typehat==1) pi0<-predict(gmm.fit0,newdata=xdf) else pi0<-predict(gmm.fit0,newdata=xdf,re.form = NA)
        }
        pi0<-expit(pi0)
        W<-diag(pi0*(1-pi0))
        H<-(W%^%(1/2))%*%xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W%^%(1/2))
        hi<-diag(H)
      }
    } else {
      hi<-rep(0,nrow(xdf$X))
    }
    
    M=c(xdf$M,hi/2,hi/2)
    
    
    pseudo<-list(X=X,
                 Z=Z,
                 Y=Y,
                 M=M,
                 grouping=grouping
    )
    
    
    if (fit.TMB==FALSE){
      gmm.fit<-glmer(Y~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer) )    
      tol2<-max(c(max(abs(fixef(gmm.fit0)-fixef(gmm.fit))),
                  max(abs(ranef(gmm.fit0)$grouping[1:N,]-ranef(gmm.fit)$grouping[1:N,])) ))
      
      
    } else {
      gmm.fit<-glmmTMB(Y~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML) 
      
      tol2<-max(c(max(abs(fixef(gmm.fit0)$cond-fixef(gmm.fit)$cond)),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping[1:N,]-ranef(gmm.fit)[[1]]$grouping[1:N,])) ))
      
    }
    
    
    if (tol2<tol) flag=TRUE
  }
  
  if (fit.TMB==FALSE){
    cfs[[nIter+1]]<-fixef(gmm.fit)
  } else {
    cfs[[nIter+1]]<-fixef(gmm.fit)$cond
  }
  
  if (plot.coef.path==TRUE){
    pp<-length(cfs[[1]])
    ce<-matrix(unlist(cfs),byrow=TRUE,ncol=pp) 
    par(mfrow=c(1,pp))
    for (i in 1:pp){
      plot(ce[,i],type="l")
    }
    
  }
  
  
  gmm.fit     
  
}



####this is the implementation of Yefrey prior as in description_v3

#data - list with elements Y, X, Z, grouping, M
#penX - TRUE sets the penalty for beta, should results in ML for FALSE
#fit.TMB TRUE uses glmmTMB, FALSE uses glmer
#REML - only applies if fit.TMB=TRUE, if TRUE uses REML for variance components, if FALSE uses ML
#plot.coef.path - plots coefficient pats for each fixef parameter
#weight.c - the multiplies of the weight, a single number: common choice either 1/2 or sqrt(p/ntot)

pen_Z_only<-function(data,tol=1e-6,maxIter=25,penX=TRUE,weight.c=1/2,fit.TMB=FALSE,REML=FALSE,plot.coef.path=FALSE,nAGQ=1,optimizer=c("bobyqa", "Nelder_Mead")){
  
  
  xdf=data
  N<-length(unique(xdf$grouping))
  Ntot<-nrow(xdf$X)
  ##here the iterative procedure starts:
  if(penX==TRUE){
     
      pi0<-rep(0.5,Ntot)
      W<-diag(pi0*(1-pi0))
      #H<-(W%^%(1/2))%*%xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W%^%(1/2))
      H<-xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%W  
      
      hi<-diag(H)
     
  } else {
    hi<-rep(0,Ntot)
  }
  
  ##add pseudoobsr:
  cfs<-list()
  
  
  flag=FALSE
  
  nIter<-0
  while(flag==FALSE&nIter<maxIter){
    nIter<-nIter+1
    
    ##add pseudoobsr:
    
    if (nIter==1) {
      
      X=rbind(xdf$X,xdf$X,xdf$X)
      
        Z=rbind(xdf$Z,matrix(0,ncol=ncol(xdf$Z),nrow=Ntot*2)) #no penalty on Z
      
      Y=c(xdf$Y,xdf$Y,1-xdf$Y)
      M=c(xdf$M,hi*weight.c,hi*weight.c)
      grouping=c(xdf$grouping,
                 seq(from=1+max(xdf$grouping),by=1,length.out = 2*Ntot)
                 )
      #grouping=rep(xdf$grouping,3) #old version, the new makes more sense (although the res are similar)
      
      
      pseudo<-list(X=X,
                   Z=Z,
                   Y=Y,
                   M=M,
                   grouping=grouping
      )
      
      
      if (fit.TMB==FALSE){
        gmm.fit0<-glmer(Y~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M ,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer))    
      } else {
        gmm.fit0<-glmmTMB(Y~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML) 
      }
    } else {
      gmm.fit0<-gmm.fit
    }
    if (fit.TMB==FALSE){
      cfs[[nIter]]<-fixef(gmm.fit0)
    } else {
      cfs[[nIter]]<-fixef(gmm.fit0)$cond
    }
    #xdf$lp<-predict(gmm.fit0,random.only=TRUE)[1:nrow(xdf$X)]
    #xdf$lp<-get.re(gmm.fit0,nrow(xdf$X),xdf$grouping,xdf$Z)
    
    if(penX==TRUE){
         if (fit.TMB==FALSE){
           pi0<-predict(gmm.fit0,re.form = NA)[1:Ntot]
        } else {
           pi0<-predict(gmm.fit0,newdata=xdf,re.form = NA)
        }
        pi0<-expit(pi0)
        W<-diag(pi0*(1-pi0))
        #H<-(W%^%(1/2))%*%xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W%^%(1/2))
        H<-xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
        hi<-diag(H)
      
    } else {
      hi<-rep(0,Ntot)
    }
    
    M=c(xdf$M,hi*weight.c,hi*weight.c)
    
    
    pseudo<-list(X=X,
                 Z=Z,
                 Y=Y,
                 M=M,
                 grouping=grouping
    )
    
    
    if (fit.TMB==FALSE){
      gmm.fit<-glmer(Y~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ,control = glmerControl(optimizer=optimizer) )    
      tol2<-max(c(max(abs(fixef(gmm.fit0)-fixef(gmm.fit))),
                  max(abs(ranef(gmm.fit0)$grouping[1:N,]-ranef(gmm.fit)$grouping[1:N,])) ))
      
      
    } else {
      gmm.fit<-glmmTMB(Y~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML) 
      
      tol2<-max(c(max(abs(fixef(gmm.fit0)$cond-fixef(gmm.fit)$cond)),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping[1:N,]-ranef(gmm.fit)[[1]]$grouping[1:N,])) ))
      
    }
    
    
    if (tol2<tol) flag=TRUE
  }
  
  if (fit.TMB==FALSE){
    cfs[[nIter+1]]<-fixef(gmm.fit)
  } else {
    cfs[[nIter+1]]<-fixef(gmm.fit)$cond
  }
  
  if (plot.coef.path==TRUE){
    pp<-length(cfs[[1]])
    ce<-matrix(unlist(cfs),byrow=TRUE,ncol=pp) 
    par(mfrow=c(1,pp))
    for (i in 1:pp){
      plot(ce[,i],type="l")
    }
    
  }
  
  
  gmm.fit     
  
}


#version where we add prior on Z, only works for models with RE int and slope, but could be easily generalized

#psevdo_data_Z what you get from a call to 
#make_pseudo_data_rand<-function(var.int,var.re,rho,use_optim=FALSE,grid=NULL,show_plot=FALSE)

#psevdo_data_Z<-make_pseudo_data_rand(var.int=2,var.slope =5,rho=0.5)
#true.sigma<-matrix(c(2,0.5*sqrt(10),0.5*sqrt(10),5),ncol=2)
#data<-make.data(5,20,3,c(4,2,0),-2,var.random.inter=2,var.random.slope=5,cov.re=0.5*sqrt(10))
#tol=1e-6
#maxIter=25
#penX=TRUE
#penZ=FALSE
#fit.TMB=FALSE
#REML=FALSE
#plot.coef.path=TRUE
#fit.frth=TRUE



rok.glmm.general.iter<-function(data,psevdo_data_Z,tol=1e-6,maxIter=25,penX=TRUE,penZ=FALSE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=FALSE,fit.frth=TRUE,nAGQ=1,typehat=1){
  
 # if (is.null(weightz)) weightz<-rep(1,length(psevdo_data_Z$data$Y))
  
  weightz<-rep(1,length(psevdo_data_Z$data$Y))
  #weighth<-psevdo_data_Z$data$nn[1] #using this makes no sense at all, we get very weird results also for fixef!
  weighth<-1
  xdf=data
  N<-length(unique(xdf$grouping))
  ##here the iterative procedure starts:
  if(penX==TRUE){
    if (fit.frth==TRUE){
      firth<-logistf(Y~-1+X,data=xdf,pl=FALSE,firth=TRUE)
      hi<-firth$hat.diag
    } else {
      pi0<-rep(0.5,nrow(xdf$X))
      W<-diag(pi0*(1-pi0))
      H<-(W%^%(1/2))%*%xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W%^%(1/2))
      hi<-diag(H)
    }
  } else {
    hi<-rep(0,nrow(xdf$X))
  }
  
  ##add pseudoobsr:
  cfs<-list()
  
  
  flag=FALSE
  
  nIter<-0
  while(flag==FALSE&nIter<maxIter){
    nIter<-nIter+1
    
    ##add pseudoobsr:
    
    if (nIter==1) {
      
      X=rbind(xdf$X,xdf$X,xdf$X,matrix(0,ncol=ncol(xdf$X),nrow=nrow(psevdo_data_Z$data$Z)))
      if (penZ==FALSE){
        ZZ=rbind(xdf$Z,matrix(0,ncol=ncol(xdf$Z),nrow=nrow(xdf$Z)*2)) #no penalty on Z
      } else {
        ZZ=rbind(xdf$Z,xdf$Z,xdf$Z) #georg
      }
      Z=rbind(ZZ,psevdo_data_Z$data$Z)
      Y=c(xdf$Y,xdf$Y,1-xdf$Y,psevdo_data_Z$data$Y)
      M=c(xdf$M*weighth,hi/2*weighth,hi/2*weighth,weightz)
      nn=c(rep(1,nrow(ZZ)),psevdo_data_Z$data$nn)
      groupingi=c(xdf$grouping,
                 xdf$grouping+max(xdf$grouping),xdf$grouping+2*max(xdf$grouping))
      grouping=c(groupingi,psevdo_data_Z$data$grouping+max(groupingi))
      #grouping=rep(xdf$grouping,3) #old version, the new makes more sense (although the res are similar)
      
      
      pseudo<-list(X=X,
                   Z=Z,
                   Y=Y,
                   M=M,
                   grouping=grouping,
                   nn=nn
      )
      
      
      if (fit.TMB==FALSE){
        gmm.fit0<-glmer(cbind(Y,nn-Y)~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ )    
      } else {
        gmm.fit0<-glmmTMB(cbind(Y,nn-Y)~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML) 
      }
    } else {
      gmm.fit0<-gmm.fit
    }
    if (fit.TMB==FALSE){
      cfs[[nIter]]<-fixef(gmm.fit0)
    } else {
      cfs[[nIter]]<-fixef(gmm.fit0)$cond
    }
    #xdf$lp<-predict(gmm.fit0,random.only=TRUE)[1:nrow(xdf$X)]
    xdf$lp<-get.re(gmm.fit0,nrow(xdf$X),xdf$grouping,xdf$Z)
    
    if(penX==TRUE){
      if (fit.frth==TRUE){
        firth<-logistf(Y~-1+X+offset(lp),data=xdf,pl=FALSE,firth=TRUE)
        hi<-firth$hat.diag
      } else {
        if (fit.TMB==FALSE){
          if (typehat==1) pi0<-predict(gmm.fit0)[1:nrow(xdf$X)] else pi0<-predict(gmm.fit0,re.form = NA)[1:nrow(xdf$X)]
        } else {
          if (typehat==1) pi0<-predict(gmm.fit0,newdata=xdf) else pi0<-predict(gmm.fit0,newdata=xdf,re.form = NA)
        }
        pi0<-expit(pi0)
        W<-diag(pi0*(1-pi0))
        H<-(W%^%(1/2))%*%xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W%^%(1/2))
        hi<-diag(H)
      }
    } else {
      hi<-rep(0,nrow(xdf$X))
    }
    
    M=c(xdf$M*weighth,hi/2*weighth,hi/2*weighth,weightz)
    
    
    pseudo<-list(X=X,
                 Z=Z,
                 Y=Y,
                 M=M,
                 grouping=grouping
    )
    
    
    if (fit.TMB==FALSE){
      gmm.fit<-glmer(cbind(Y,nn-Y)~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ )    
      tol2<-max(c(max(abs(fixef(gmm.fit0)-fixef(gmm.fit))),
                  max(abs(ranef(gmm.fit0)$grouping[1:N,]-ranef(gmm.fit)$grouping[1:N,])) ))
      
      
    } else {
      gmm.fit<-glmmTMB(cbind(Y,nn-Y)~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML) 
      
      tol2<-max(c(max(abs(fixef(gmm.fit0)$cond-fixef(gmm.fit)$cond)),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping[1:N,]-ranef(gmm.fit)[[1]]$grouping[1:N,])) ))
      
    }
    
    
    if (tol2<tol) flag=TRUE
  }
  
  if (fit.TMB==FALSE){
    cfs[[nIter+1]]<-fixef(gmm.fit)
  } else {
    cfs[[nIter+1]]<-fixef(gmm.fit)$cond
  }
  
  if (plot.coef.path==TRUE){
    pp<-length(cfs[[1]])
    ce<-matrix(unlist(cfs),byrow=TRUE,ncol=pp) 
    par(mfrow=c(1,pp))
    for (i in 1:pp){
      plot(ce[,i],type="l")
    }
    
  }
  
  
  gmm.fit     
  
}





#version where we add prior on Z, with fixef penalty as in description_v3

#psevdo_data_Z what you get from a call to either 
#make_pseudo_data_rand_eigen_general for q>1 or 
#make_pseudo_data_rand_eigen_inter for q=1
#the other params are as described for pen_Z_only 
#tol=1e-6
#maxIter=25
#penX=TRUE 
#fit.TMB=FALSE
#REML=FALSE
#plot.coef.path=TRUE
#weight.c 


pen_both<-function(data,psevdo_data_Z,weight.c=1/2,tol=1e-6,maxIter=25,penX=TRUE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=FALSE,nAGQ=1){
  
  # if (is.null(weightz)) weightz<-rep(1,length(psevdo_data_Z$data$Y))
  
  weightz<-rep(1,length(psevdo_data_Z$data$Y))
  #weighth<-psevdo_data_Z$data$nn[1] #using this makes no sense at all, we get very weird results also for fixef!
  weighth<-1
  xdf=data
  N<-length(unique(xdf$grouping))
  Ntot<-nrow(xdf$X)
  ##here the iterative procedure starts:
  if(penX==TRUE){
     
      pi0<-rep(0.5,Ntot)
      W<-diag(pi0*(1-pi0))
      H<- xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
      hi<-diag(H)
     
  } else {
    hi<-rep(0,Ntot)
  }
  
  ##add pseudoobsr:
  cfs<-list()
  
  
  flag=FALSE
  
  nIter<-0
  while(flag==FALSE&nIter<maxIter){
    nIter<-nIter+1
    
    ##add pseudoobsr:
    
    if (nIter==1) {
      
      X=rbind(xdf$X,xdf$X,xdf$X,matrix(0,ncol=ncol(xdf$X),nrow=nrow(psevdo_data_Z$data$Z)))
       
      ZZ=rbind(xdf$Z,matrix(0,ncol=ncol(xdf$Z),nrow=Ntot*2)) #no penalty on Z
       
      Z=rbind(ZZ,psevdo_data_Z$data$Z)
      Y=c(xdf$Y,xdf$Y,1-xdf$Y,psevdo_data_Z$data$Y)
      M=c(xdf$M*weighth,hi*weight.c*weighth,hi*weight.c*weighth,weightz)
      nn=c(rep(1,nrow(ZZ)),psevdo_data_Z$data$nn)
      groupingi=c(xdf$grouping,
                  seq(from=1+max(xdf$grouping),by=1,length.out = 2*Ntot)  )
      grouping=c(groupingi,psevdo_data_Z$data$grouping+max(groupingi))
      #grouping=rep(xdf$grouping,3) #old version, the new makes more sense (although the res are similar)
      
      
      pseudo<-list(X=X,
                   Z=Z,
                   Y=Y,
                   M=M,
                   grouping=grouping,
                   nn=nn
      )
      
      
      if (fit.TMB==FALSE){
        gmm.fit0<-glmer(cbind(Y,nn-Y)~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ )    
      } else {
        gmm.fit0<-glmmTMB(cbind(Y,nn-Y)~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML) 
      }
    } else {
      gmm.fit0<-gmm.fit
    }
    if (fit.TMB==FALSE){
      cfs[[nIter]]<-fixef(gmm.fit0)
    } else {
      cfs[[nIter]]<-fixef(gmm.fit0)$cond
    }
    #xdf$lp<-predict(gmm.fit0,random.only=TRUE)[1:nrow(xdf$X)]
    #xdf$lp<-get.re(gmm.fit0,nrow(xdf$X),xdf$grouping,xdf$Z)
    
    if(penX==TRUE){
       
        if (fit.TMB==FALSE){
          pi0<-predict(gmm.fit0,re.form = NA)[1:Ntot]
        } else {
          pi0<-predict(gmm.fit0,newdata=xdf,re.form = NA)
        }
        pi0<-expit(pi0)
        W<-diag(pi0*(1-pi0))
        H<-xdf$X%*%solve(t(xdf$X)%*%W%*%xdf$X)%*%t(xdf$X)%*%(W)
        hi<-diag(H)
       
    } else {
      hi<-rep(0,Ntot)
    }
    
    M=c(xdf$M*weighth,hi*weight.c*weighth,hi*weight.c*weighth,weightz)
    
    
    pseudo<-list(X=X,
                 Z=Z,
                 Y=Y,
                 M=M,
                 grouping=grouping
    )
    
    
    if (fit.TMB==FALSE){
      gmm.fit<-glmer(cbind(Y,nn-Y)~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M,nAGQ=nAGQ )    
      tol2<-max(c(max(abs(fixef(gmm.fit0)-fixef(gmm.fit))),
                  max(abs(ranef(gmm.fit0)$grouping[1:N,]-ranef(gmm.fit)$grouping[1:N,])) ))
      
      
    } else {
      gmm.fit<-glmmTMB(cbind(Y,nn-Y)~-1+X+(-1+Z|grouping), data = pseudo, family = binomial(link="logit"),weights=M, se = TRUE, verbose = FALSE, doFit = TRUE, REML = REML) 
      
      tol2<-max(c(max(abs(fixef(gmm.fit0)$cond-fixef(gmm.fit)$cond)),
                  max(abs(ranef(gmm.fit0)[[1]]$grouping[1:N,]-ranef(gmm.fit)[[1]]$grouping[1:N,])) ))
      
    }
    
    
    if (tol2<tol) flag=TRUE
  }
  
  if (fit.TMB==FALSE){
    cfs[[nIter+1]]<-fixef(gmm.fit)
  } else {
    cfs[[nIter+1]]<-fixef(gmm.fit)$cond
  }
  
  if (plot.coef.path==TRUE){
    pp<-length(cfs[[1]])
    ce<-matrix(unlist(cfs),byrow=TRUE,ncol=pp) 
    par(mfrow=c(1,pp))
    for (i in 1:pp){
      plot(ce[,i],type="l")
    }
    
  }
  
  
  gmm.fit     
  
}




#aux function to get D for Kosmidis parametrization

getsigma<-function(x,p){
  L<-rbind(c(exp(x[p+1,1]),0),
           c(x[p+2,1],exp(x[p+3,1])))
  L%*%t(L)
}




####an example of a simulation

vr=5
vi=2
rh=0.4
n=10
N=50

true.sigma<-matrix(c(vi,rh*sqrt(vi*vr),rh*sqrt(vi*vr),vr),ncol=2)
psevdo_data_Z<-make_pseudo_data_rand_eigen_general(true.sigma) #correct

wrong.sigma<-matrix(c(2,0.8*sqrt(2*10),0.8*sqrt(2*10),10),ncol=2)
psevdo_data_Z_w<-make_pseudo_data_rand_eigen_general(wrong.sigma,fact=2) #wrong to see


B<-100
plt=FALSE
sresh1<-sresh2<-sresh3<-sresh4<-
 resh1<-resh2<-resh3<-resh4<-resh5<-matrix(NA,ncol=4+4,nrow=B)
 reshw<-resh1w<-matrix(NA,ncol=4+4,nrow=B)
 k1<-kt<-kn<-matrix(NA,ncol=4+4,nrow=B)
for (ii in 1:B){
  
  data<-make.data(n,N,3,c(4,2,0),-2,var.random.inter=vi,var.random.slope=vr,cov.re=rh*sqrt(vr*vi))
  
  data$Y[data$Y==1&data$X[,2]==1]<-0  
  
  rfit<-try(rok.glmm.general.iter(data=data,psevdo_data_Z=psevdo_data_Z,tol=1e-6,maxIter=25,penX=TRUE,penZ=FALSE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=plt,fit.frth=FALSE),silent=TRUE) #rok, both penalized, using the "correct" prior
  rfit1<-try(rok.glmm.general.iter(data=data,psevdo_data_Z=psevdo_data_Z,tol=1e-6,maxIter=25,penX=FALSE,penZ=FALSE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=plt,fit.frth=FALSE),silent=TRUE) #rok, penalize only Z, using the "correct" prior
  
  #bayes version
  
  bfit<-bglmer(Y~-1+X+(-1+Z|grouping),data=data,family=binomial(link = "logit"),
               cov.prior = grouping~wishart(df=2*ncol(true.sigma)+1,scale=solve(true.sigma)/ncol(true.sigma)))
  
  bfit1<-bglmer(Y~-1+X+(-1+Z|grouping),data=data,family=binomial(link = "logit"),
               cov.prior = grouping~invwishart(df=2*ncol(true.sigma)+1,scale=true.sigma*ncol(true.sigma)))
  
  
  
  sfit<-try(rok.glmm.general.iter.sample(data=data,tol=1e-6,maxIter=25,penX=TRUE,penZ=FALSE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=plt,fit.frth=FALSE),silent=TRUE) #rok, both penalized, using the "correct" prior
  sfit1<-try(rok.glmm.general.iter.sample(data=data,tol=1e-6,maxIter=25,penX=FALSE,penZ=FALSE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=plt,fit.frth=FALSE),silent=TRUE) #rok, penalize only Z, using the "correct" prior
  
  if (class(sfit)!="try-error"){
    ff.rr.o<-fixef(sfit)
    sigma.rr.o<-try(VarCorr(sfit)$grouping[1:2,1:2],silent=TRUE)
    if (class(sigma.rr.o)=="try-error") sigma.rr.o<-rep(NA,4)
    sresh1[ii,]<-c(ff.rr.o,c(sigma.rr.o))
  }
  
  if (class(sfit1)!="try-error"){
    ff.rr.o1<-fixef(sfit1)
    sigma.rr.o1<-try(VarCorr(sfit1)$grouping[1:2,1:2],silent=TRUE)
    if (class(sigma.rr.o1)=="try-error") sigma.rr.o1<-rep(NA,4)
    sresh2[ii,]<-c(ff.rr.o1,c(sigma.rr.o1))
  }
  
  gfit<-try(georg.glmm.general.iter(data,tol=1e-6,maxIter=25,penX=TRUE,penZ=TRUE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=plt,fit.frth=FALSE),silent=TRUE) #georg
  gfit1<-try(georg.glmm.general.iter(data,tol=1e-6,maxIter=25,penX=TRUE,penZ=FALSE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=plt,fit.frth=FALSE),silent=TRUE) #Yef for X, no pen for Z
   
  fitc<-try(glmer(Y~-1+X+(-1+Z|grouping),data=data,family=binomial(link = "logit")),silent=TRUE) #glmer
  if (class(fitc)!="try-error"){
    ss<-recoversigma(fitc)
    sti=ss[1]
    sts=ss[2]
    str=ss[3]
  } else {
    sti=sts=1
    str=0
  }
  sfit3<-try(rok.glmm.general.iter.sample(data=data,
                                          start.int=sti,start.slope=sts,start.rho=str,tol=1e-6,maxIter=25,penX=TRUE,penZ=FALSE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=plt,fit.frth=FALSE),silent=TRUE) #rok, both penalized, using the "correct" prior
  sfit4<-try(rok.glmm.general.iter.sample(data=data,
                                          start.int=sti,start.slope=sts,start.rho=str,tol=1e-6,maxIter=25,penX=FALSE,penZ=FALSE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=plt,fit.frth=FALSE),silent=TRUE) #rok, penalize only Z, using the "correct" prior
  
  if (class(sfit3)!="try-error"){
    ff.rr.o<-fixef(sfit3)
    sigma.rr.o<-try(VarCorr(sfit3)$grouping[1:2,1:2],silent=TRUE)
    if (class(sigma.rr.o)=="try-error") sigma.rr.o<-rep(NA,4)
    sresh3[ii,]<-c(ff.rr.o,c(sigma.rr.o))
  }
  
  if (class(sfit4)!="try-error"){
    ff.rr.o1<-fixef(sfit4)
    sigma.rr.o1<-try(VarCorr(sfit4)$grouping[1:2,1:2],silent=TRUE)
    if (class(sigma.rr.o1)=="try-error") sigma.rr.o1<-rep(NA,4)
    sresh4[ii,]<-c(ff.rr.o1,c(sigma.rr.o1))
  }
  
  rfitw<-try(rok.glmm.general.iter(data=data,psevdo_data_Z=psevdo_data_Z_w,tol=1e-6,maxIter=25,penX=TRUE,penZ=FALSE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=plt,fit.frth=FALSE),silent=TRUE) #rok, both penalized, using a "wrong" prior 
  rfit1w<-try(rok.glmm.general.iter(data=data,psevdo_data_Z=psevdo_data_Z_w,tol=1e-6,maxIter=25,penX=FALSE,penZ=FALSE,fit.TMB=FALSE,REML=FALSE,plot.coef.path=plt,fit.frth=FALSE),silent=TRUE) #rok, penalize only Z, using a "wrong" prior
  
  
  
  p <- ncol(data$X)
  q <- max(1, ncol(data$Z))
  npar <- p + 0.5 * q * (q + 1)
  cond_inf_results <- try(mv_fit_all(start = rep(0, npar), data = data),
                          silent=TRUE)
  
  
  
   
  if (class(cond_inf_results)=="try-error"){ 
    sigma.mspl<-sigma.t<-sigma.n<-rep(NA,length(c(true.sigma)))
    ff.mspl<-ff.t<-ff.n<-rep(NA,p)
    
    
  } else {
    sigma.mspl<-getsigma(cond_inf_results$MSPL,p=p)
    ff.mspl<-cond_inf_results$MSPL[1:p,1]
      
    sigma.t<-getsigma(cond_inf_results$bglmer_t,p=p)
    ff.t<-cond_inf_results$bglmer_t[1:p,1]
        
    sigma.n<-getsigma(cond_inf_results$bglmer_n,p=p)
    ff.n<-cond_inf_results$bglmer_n[1:p,1]
    
      
    
  }
  k1[ii,]<-c(ff.mspl,c(sigma.mspl))
  kt[ii,]<-c(ff.t,c(sigma.t))
  kn[ii,]<-c(ff.n,c(sigma.n))
  
  if (class(gfit)!="try-error"){
    ff.rr.og<-fixef(gfit)
    sigma.rr.og<-try(VarCorr(gfit)$grouping[1:2,1:2],silent=TRUE)
    if (class(sigma.rr.og)=="try-error") sigma.rr.og<-rep(NA,4)
    resh4[ii,]<-c(ff.rr.og,c(sigma.rr.og))
  }
  
  if (class(gfit1)!="try-error"){
    ff.rr.og1<-fixef(gfit1)
    sigma.rr.og1<-try(VarCorr(gfit1)$grouping[1:2,1:2],silent=TRUE)
    if (class(sigma.rr.og1)=="try-error") sigma.rr.og1<-rep(NA,4)
    resh5[ii,]<-c(ff.rr.og1,c(sigma.rr.og1))
  }
  
  
  if (class(rfitw)!="try-error"){
    ff.rr.ow<-fixef(rfitw)
    sigma.rr.ow<-try(VarCorr(rfitw)$grouping[1:2,1:2],silent=TRUE)
    if (class(sigma.rr.ow)=="try-error") sigma.rr.ow<-rep(NA,4)
    reshw[ii,]<-c(ff.rr.ow,c(sigma.rr.ow))
  }
  if (class(rfit1w)!="try-error"){
    ff.rr.o1w<-fixef(rfit1w)
    sigma.rr.o1w<-try(VarCorr(rfit1w)$grouping[1:2,1:2],silent=TRUE)
    if (class(sigma.rr.o1w)=="try-error") sigma.rr.o1w<-rep(NA,4)
    resh1w[ii,]<-c(ff.rr.o1w,c(sigma.rr.o1w))
  } 
  
  if (class(rfit)!="try-error"){
  ff.rr.o<-fixef(rfit)
  sigma.rr.o<-try(VarCorr(rfit)$grouping[1:2,1:2],silent=TRUE)
  if (class(sigma.rr.o)=="try-error") sigma.rr.o<-rep(NA,4)
  resh1[ii,]<-c(ff.rr.o,c(sigma.rr.o))
  }
  
  if (class(rfit1)!="try-error"){
  ff.rr.o1<-fixef(rfit1)
  sigma.rr.o1<-try(VarCorr(rfit1)$grouping[1:2,1:2],silent=TRUE)
  if (class(sigma.rr.o1)=="try-error") sigma.rr.o1<-rep(NA,4)
  resh2[ii,]<-c(ff.rr.o1,c(sigma.rr.o1))
  }
  
  if (class(fitc)!="try-error"){
  ff.rr.o2<-fixef(fitc)
  sigma.rr.o2<-try(VarCorr(fitc)$grouping[1:2,1:2],silent=TRUE)
  if (class(sigma.rr.o2)=="try-error") sigma.rr.o2<-rep(NA,4)
  resh3[ii,]<-c(ff.rr.o2,c(sigma.rr.o2))
  }
  
  
  print(ii)
  
}
 
 true.param<-matrix(c(-2,4,2,0,c(true.sigma)),ncol=8,nrow=B,byrow=TRUE)
 
 myna1<-function(x) if (sum(is.na(x))>0) 1 else 0
 myna<-function(x,p) if (sum(is.na(x))==p) 1 else 0
sum(apply(resh1,1,myna,ncol(resh1)))
sum(apply(resh2,1,myna,ncol(resh1)))
sum(apply(sresh1,1,myna,ncol(resh1)))
sum(apply(sresh2,1,myna,ncol(resh1)))
sum(apply(sresh3,1,myna,ncol(resh1)))
sum(apply(sresh4,1,myna,ncol(resh1)))

sum(apply(resh3,1,myna,ncol(resh1)))
sum(apply(resh4,1,myna,ncol(resh1)))
sum(apply(resh5,1,myna,ncol(resh1)))
sum(apply(reshw,1,myna,ncol(resh1)))
sum(apply(resh1w,1,myna,ncol(resh1)))
sum(apply(k1,1,myna,ncol(resh1)))
sum(apply(kt,1,myna,ncol(resh1)))
sum(apply(kn,1,myna,ncol(resh1)))


sum(apply(resh1,1,myna1))
sum(apply(resh2,1,myna1))
sum(apply(sresh1,1,myna1))
sum(apply(sresh2,1,myna1))
sum(apply(sresh3,1,myna1))
sum(apply(sresh4,1,myna1))

sum(apply(resh3,1,myna1))
sum(apply(resh4,1,myna1))
sum(apply(resh5,1,myna1))
sum(apply(reshw,1,myna1))
sum(apply(resh1w,1,myna1))
sum(apply(k1,1,myna1))
sum(apply(kt,1,myna1))
sum(apply(kn,1,myna1))



apply(resh1,2,mean,na.rm=TRUE)  
apply(resh2,2,mean,na.rm=TRUE) 
apply(sresh1,2,mean,na.rm=TRUE)  
apply(sresh2,2,mean,na.rm=TRUE) 
apply(sresh3,2,mean,na.rm=TRUE)  
apply(sresh4,2,mean,na.rm=TRUE) 

apply(resh3,2,mean,na.rm=TRUE)  
apply(resh4,2,mean,na.rm=TRUE)  
apply(resh5,2,mean,na.rm=TRUE)  
apply(reshw,2,mean,na.rm=TRUE)  
apply(resh1w,2,mean,na.rm=TRUE) 
apply(k1,2,mean,na.rm=TRUE) 
apply(kt,2,mean,na.rm=TRUE) 
apply(kn,2,mean,na.rm=TRUE) 


 par(mfrow=c(1,2),mar=c(2,2,1,1))
boxplot(cbind(resh1[,1:4]-true.param[,1:4],
              sresh1[,1:4]-true.param[,1:4],
              sresh3[,1:4]-true.param[,1:4],
             # resh2[,1:4]-true.param[,1:4],
             # resh3[,1:4]-true.param[,1:4],
             # resh4[,1:4]-true.param[,1:4],
            #  resh5[,1:4]-true.param[,1:4],
              reshw[,1:4]-true.param[,1:4],#,
            k1[,1:4]-true.param[,1:4]
            #  resh1w[,1:4]-true.param[,1:4]
            ))
abline(h=0)
#boxplot(cbind(resh1[,1:4]-true.param[,1:4],
 #             resh2[,1:4]-true.param[,1:4],
  #            resh4[,1:4]-true.param[,1:4],
   #           resh5[,1:4]-true.param[,1:4]))
#abline(h=0)

boxplot(cbind(resh1[,c(5,6,8)]-true.param[,c(5,6,8)],
              sresh1[,c(5,6,8)]-true.param[,c(5,6,8)],
              sresh4[,c(5,6,8)]-true.param[,c(5,6,8)],
            #  resh2[,c(5,6,8)]-true.param[,c(5,6,8)],
             # resh3[,c(5,6,8)]-true.param[,c(5,6,8)],
            #  resh4[,c(5,6,8)]-true.param[,c(5,6,8)],
            #  resh5[,c(5,6,8)]-true.param[,c(5,6,8)]
            reshw[,c(5,6,8)]-true.param[,c(5,6,8)],#,
            k1[,c(5,6,8)]-true.param[,c(5,6,8)]
            #resh1w[,c(5,6,8)]-true.param[,c(5,6,8)]
             ))
abline(h=0)

boxplot(cbind(resh1[,c(5,6,8)]-true.param[,c(5,6,8)],
              resh2[,c(5,6,8)]-true.param[,c(5,6,8)],
              resh4[,c(5,6,8)]-true.param[,c(5,6,8)],
              resh5[,c(5,6,8)]-true.param[,c(5,6,8)]
))
abline(h=0)


mysum<-function(x,true){
  b<-apply(x,2,mean,na.rm=TRUE)-true
  v<-apply(x,2,var,na.rm=TRUE)
  m<-b^2+v
  res<-cbind(b,v,m)
  colnames(res)<-c("b","v","m")
  res
}

mysum(resh1,c(-2,4,2,0,c(true.sigma)))
mysum(resh2,c(-2,4,2,0,c(true.sigma)))
mysum(sresh1,c(-2,4,2,0,c(true.sigma)))
mysum(sresh2,c(-2,4,2,0,c(true.sigma)))
mysum(sresh3,c(-2,4,2,0,c(true.sigma)))
mysum(sresh4,c(-2,4,2,0,c(true.sigma)))

mysum(resh3,c(-2,4,2,0,c(true.sigma)))
mysum(resh4,c(-2,4,2,0,c(true.sigma)))
mysum(resh5,c(-2,4,2,0,c(true.sigma)))

mysum(k1,c(-2,4,2,0,c(true.sigma)))
mysum(reshw,c(-2,4,2,0,c(true.sigma)))

